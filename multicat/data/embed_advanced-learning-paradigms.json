{"category":{"name":"Advanced Learning Paradigms","normalized_name":"advanced-learning-paradigms","subcategories":[{"name":"Federated Learning and Privacy","normalized_name":"federated-learning-and-privacy"},{"name":"Continual Learning","normalized_name":"continual-learning"},{"name":"Model Distillation and Transfer Learning","normalized_name":"model-distillation-and-transfer-learning"},{"name":"Multi-modal Learning","normalized_name":"multi-modal-learning"}]},"foundation":"PyTorch","items":[{"category":"Advanced Learning Paradigms","id":"advanced-learning-paradigms--federated-learning-and-privacy--flower","name":"Flower","logo":"logos/af4acf3f0922e8bb18cd7439136d299b7c8ddd7c5b8e7574bb31c17c6b4450b1.svg","subcategory":"Federated Learning and Privacy","website":"https://flower.ai/","description":"A unified approach to federated learning, analytics, and evaluation. Federate any workload, any ML framework, and any programming language","primary_repository_url":"https://github.com/adap/flower"},{"category":"Advanced Learning Paradigms","id":"advanced-learning-paradigms--federated-learning-and-privacy--opacus","name":"Opacus","logo":"logos/93e7f58529785d31148daadf57a83ea2c2f8a5881b6825df426596b79b6954ad.svg","subcategory":"Federated Learning and Privacy","website":"https://opacus.ai/","description":"Train PyTorch models with Differential Privacy","primary_repository_url":"https://github.com/pytorch/opacus"},{"category":"Advanced Learning Paradigms","id":"advanced-learning-paradigms--federated-learning-and-privacy--pysyft","name":"PySyft","logo":"logos/ddcdd70695dcc0780072851c60375522b8a616c35ffdec80717cf32b87d21310.svg","subcategory":"Federated Learning and Privacy","website":"https://www.openmined.org/","description":"Perform data science on data that remains in someone else's server","primary_repository_url":"https://github.com/OpenMined/PySyft"},{"category":"Advanced Learning Paradigms","id":"advanced-learning-paradigms--federated-learning-and-privacy--substra","name":"Substra","logo":"logos/57e63c3a4288f965a164da315553b98b67b369bbee4e6d9a24cdfd6cb43bc380.svg","subcategory":"Federated Learning and Privacy","website":"https://docs.substra.org/","description":"Substra is used to run complex federated learning experiments at scale.","primary_repository_url":"https://github.com/Substra"},{"category":"Advanced Learning Paradigms","id":"advanced-learning-paradigms--continual-learning--avalanche","name":"avalanche","logo":"logos/6db724b646af4bb6a96bf1e939a4018ee5f01db33e92af69a611275266ba90f5.svg","subcategory":"Continual Learning","website":"http://avalanche.continualai.org/","description":"Avalanche is an End-to-End Continual Learning Library based on PyTorch, for fast prototyping, training, and reproducible evaluation of continual learning algorithms.","primary_repository_url":"https://github.com/ContinualAI/avalanche"},{"category":"Advanced Learning Paradigms","id":"advanced-learning-paradigms--continual-learning--renate","name":"Renate","logo":"logos/e9fb21ed75b6d1f586d07a501eb6f349489335f0bbc79c436f625b5f0e753577.svg","subcategory":"Continual Learning","website":"https://renate.readthedocs.io/en/latest/","description":"Renate is a Python package for automatic retraining of neural networks models. It uses advanced Continual Learning and Lifelong Learning algorithms to achieve this purpose.","primary_repository_url":"https://github.com/awslabs/renate"},{"category":"Advanced Learning Paradigms","id":"advanced-learning-paradigms--model-distillation-and-transfer-learning--pykale","name":"PyKale","logo":"logos/1514ccbb316a3ae5a772df0cb382bd6917c12793cc8174f0699d4fb19d1acec0.svg","subcategory":"Model Distillation and Transfer Learning","website":"https://pykale.github.io/","description":"PyKale has a unified pipeline-based API and focuses on multimodal learning and transfer learning for graphs, images, and videos at the moment, with supporting models on deep learning and dimensionality reduction.","primary_repository_url":"https://github.com/pykale/pykale"},{"category":"Advanced Learning Paradigms","id":"advanced-learning-paradigms--model-distillation-and-transfer-learning--torchdistill","name":"torchdistill","logo":"logos/00e6cd8399a844be633526e835a2bff2a35c27c464134204177f96b484d0b393.svg","subcategory":"Model Distillation and Transfer Learning","website":"https://yoshitomo-matsubara.net/torchdistill/","description":"Offers various state-of-the-art knowledge distillation methods and enables you to design (new) experiments simply by editing a declarative yaml config file.","primary_repository_url":"https://github.com/yoshitomo-matsubara/torchdistill"},{"category":"Advanced Learning Paradigms","id":"advanced-learning-paradigms--multi-modal-learning--mmf","name":"MMF","logo":"logos/0c6791d31524bbcc5d00788ef39db3ff6576fdd3d3b1f8cea530d5c551e9098f.svg","subcategory":"Multi-modal Learning","website":"https://mmf.sh/","description":"A modular framework for vision & language multimodal research.","primary_repository_url":"https://github.com/facebookresearch/mmf"}]}