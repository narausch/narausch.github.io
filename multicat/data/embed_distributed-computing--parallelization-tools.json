{"category":{"name":"Distributed Computing","normalized_name":"distributed-computing","subcategories":[{"name":"Parallelization tools","normalized_name":"parallelization-tools"}]},"foundation":"PyTorch","items":[{"category":"Distributed Computing","id":"distributed-computing--parallelization-tools--clear-ml","name":"Clear ML","logo":"logos/b8f9b0d3ee7df42d688ddfaf95b3177f256d68521167ac27b601778e339fbedc.svg","subcategory":"Parallelization tools","website":"https://clear.ml/","description":"Suite of tools to streamline your AI workflow.","primary_repository_url":"https://github.com/allegroai/clearml"},{"category":"Distributed Computing","id":"distributed-computing--parallelization-tools--determined","name":"Determined","logo":"logos/6f06ce54ac2345f4d76475807a8d81d20d4f6d8f1f017ac591fb22f312ef329c.svg","subcategory":"Parallelization tools","website":"https://determined.ai/","description":"Determined is an open-source machine learning platform that simplifies distributed training, hyperparameter tuning, experiment tracking, and resource management. Works with PyTorch and TensorFlow.","primary_repository_url":"https://github.com/determined-ai/determined"},{"category":"Distributed Computing","id":"distributed-computing--parallelization-tools--dgl","name":"DGL","logo":"logos/8bc26a2c13a583b1695caeee24b08ead02adb0d16645e0d2763ea37305fae388.svg","subcategory":"Parallelization tools","website":"https://www.dgl.ai/","description":"Python package built to ease deep learning on graph, on top of existing DL frameworks.  Fast and memory-efficient message passing primitives for training Graph Neural Networks.","primary_repository_url":"https://github.com/dmlc/dgl/"},{"category":"Distributed Computing","id":"distributed-computing--parallelization-tools--fastai","name":"fastai","logo":"logos/9b1d9cefe662d9c4a595cbe44fddc8c2d31a2390f6ac3ac0ae025a8c878a53ce.svg","subcategory":"Parallelization tools","website":"https://docs.fast.ai/","description":"fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches","primary_repository_url":"https://github.com/fastai/fastai"},{"category":"Distributed Computing","id":"distributed-computing--parallelization-tools--ivy","name":"ivy","logo":"logos/4ac7177a12ab6aa7b56c2420367cbe3b6e1be0de2f9753d69198f5ca9a7731bb.svg","subcategory":"Parallelization tools","website":"https://ivy.dev/","description":"Convert Machine Learning Code Between Frameworks","primary_repository_url":"https://github.com/ivy-llc/ivy"},{"category":"Distributed Computing","id":"distributed-computing--parallelization-tools--octoml-profiler","name":"OctoML Profiler","logo":"logos/6a0430bf99ada8d6b9a2f7c296d8719bd6d5081f40036783c1ee51c58ae73217.svg","subcategory":"Parallelization tools","website":"https://github.com/octoml/octoml-profile","description":"octoml-profile is a python library and cloud service that enables ML engineers to easily assess the performance and cost of PyTorch models on cloud hardware with state-of-the-art ML acceleration technology.","primary_repository_url":"https://github.com/octoml/octoml-profile"},{"category":"Distributed Computing","id":"distributed-computing--parallelization-tools--pysyft","name":"PySyft","logo":"logos/ddcdd70695dcc0780072851c60375522b8a616c35ffdec80717cf32b87d21310.svg","subcategory":"Parallelization tools","website":"https://www.openmined.org/","description":"Perform data science on data that remains in someone else's server","primary_repository_url":"https://github.com/OpenMined/PySyft"}]}