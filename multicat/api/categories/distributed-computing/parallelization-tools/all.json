[{"category":"Distributed Computing","homepage_url":"https://clear.ml/","id":"distributed-computing--parallelization-tools--clear-ml","logo_url":"http://127.0.0.1:8000/logos/b8f9b0d3ee7df42d688ddfaf95b3177f256d68521167ac27b601778e339fbedc.svg","name":"Clear ML","subcategory":"Parallelization tools","description":"Suite of tools to streamline your AI workflow.","repositories":[{"url":"https://github.com/allegroai/clearml","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://determined.ai/","id":"distributed-computing--parallelization-tools--determined","logo_url":"http://127.0.0.1:8000/logos/6f06ce54ac2345f4d76475807a8d81d20d4f6d8f1f017ac591fb22f312ef329c.svg","name":"Determined","subcategory":"Parallelization tools","description":"Determined is an open-source machine learning platform that simplifies distributed training, hyperparameter tuning, experiment tracking, and resource management. Works with PyTorch and TensorFlow.","repositories":[{"url":"https://github.com/determined-ai/determined","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://www.dgl.ai/","id":"distributed-computing--parallelization-tools--dgl","logo_url":"http://127.0.0.1:8000/logos/8bc26a2c13a583b1695caeee24b08ead02adb0d16645e0d2763ea37305fae388.svg","name":"DGL","subcategory":"Parallelization tools","description":"Python package built to ease deep learning on graph, on top of existing DL frameworks.  Fast and memory-efficient message passing primitives for training Graph Neural Networks.","repositories":[{"url":"https://github.com/dmlc/dgl/","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://docs.fast.ai/","id":"distributed-computing--parallelization-tools--fastai","logo_url":"http://127.0.0.1:8000/logos/9b1d9cefe662d9c4a595cbe44fddc8c2d31a2390f6ac3ac0ae025a8c878a53ce.svg","name":"fastai","subcategory":"Parallelization tools","description":"fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches","repositories":[{"url":"https://github.com/fastai/fastai","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://ivy.dev/","id":"distributed-computing--parallelization-tools--ivy","logo_url":"http://127.0.0.1:8000/logos/4ac7177a12ab6aa7b56c2420367cbe3b6e1be0de2f9753d69198f5ca9a7731bb.svg","name":"ivy","subcategory":"Parallelization tools","description":"Convert Machine Learning Code Between Frameworks","repositories":[{"url":"https://github.com/ivy-llc/ivy","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://github.com/octoml/octoml-profile","id":"distributed-computing--parallelization-tools--octoml-profiler","logo_url":"http://127.0.0.1:8000/logos/6a0430bf99ada8d6b9a2f7c296d8719bd6d5081f40036783c1ee51c58ae73217.svg","name":"OctoML Profiler","subcategory":"Parallelization tools","description":"octoml-profile is a python library and cloud service that enables ML engineers to easily assess the performance and cost of PyTorch models on cloud hardware with state-of-the-art ML acceleration technology.","repositories":[{"url":"https://github.com/octoml/octoml-profile","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://www.openmined.org/","id":"distributed-computing--parallelization-tools--pysyft","logo_url":"http://127.0.0.1:8000/logos/ddcdd70695dcc0780072851c60375522b8a616c35ffdec80717cf32b87d21310.svg","name":"PySyft","subcategory":"Parallelization tools","description":"Perform data science on data that remains in someone else's server","repositories":[{"url":"https://github.com/OpenMined/PySyft","primary":true}]}]