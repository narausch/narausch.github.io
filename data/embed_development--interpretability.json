{"category":{"name":"Development","normalized_name":"development","subcategories":[{"name":"Interpretability","normalized_name":"interpretability"}]},"foundation":"PyTorch","items":[{"category":"Development","id":"development--interpretability--captum","name":"Captum","logo":"logos/2abc1fc7558376c329b2798f7bcde761b3644e8805d84dc631370e0e76d75b8d.svg","subcategory":"Interpretability","website":"https://captum.ai/docs/introduction.html","description":"An open source, extensible library for model interpretability built on PyTorch.","primary_repository_url":"https://github.com/pytorch/captum"},{"category":"Development","id":"development--interpretability--opencompass","name":"OpenCompass","logo":"logos/7a70f2cbec75cbed6adfa360674d53e5fd6536ee1b342b52588a3dbd35ef8860.svg","subcategory":"Interpretability","website":"https://opencompass.org.cn/home","description":"OpenCompass is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets.","primary_repository_url":"https://github.com/open-compass/opencompass"}]}