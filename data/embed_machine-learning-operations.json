{"category":{"name":"Machine Learning Operations","normalized_name":"machine-learning-operations","subcategories":[{"name":"Parallelization tools","normalized_name":"parallelization-tools"},{"name":"Performance optimization","normalized_name":"performance-optimization"},{"name":"Interpretability","normalized_name":"interpretability"},{"name":"Experimentation","normalized_name":"experimentation"}]},"foundation":"PyTorch","items":[{"category":"Machine Learning Operations","id":"machine-learning-operations--parallelization-tools--clear-ml","name":"Clear ML","logo":"logos/6b14333eb730fab0144979bb8029431b0c677e02dfd2944f381b7e96e31054ce.svg","subcategory":"Parallelization tools","website":"https://clear.ml/","description":"Suite of tools to streamline your AI workflow.","primary_repository_url":"https://github.com/allegroai/clearml"},{"category":"Machine Learning Operations","id":"machine-learning-operations--parallelization-tools--colossalai","name":"ColossalAI","logo":"logos/2125379104f8c98deea6e3dd3e0b2af88238792c2f41420624c1a142642c69ca.svg","subcategory":"Parallelization tools","website":"https://www.colossalai.org/","description":"Tools to kickstart distributed training and inference","primary_repository_url":"https://github.com/hpcaitech/ColossalAI"},{"category":"Machine Learning Operations","id":"machine-learning-operations--parallelization-tools--composer","name":"composer","logo":"logos/6b14333eb730fab0144979bb8029431b0c677e02dfd2944f381b7e96e31054ce.svg","subcategory":"Parallelization tools","website":"http://docs.mosaicml.com/","description":"A open-source deep learning training library optimized for scalability and usability, integrating best practices for efficient, multi-node training","primary_repository_url":"https://github.com/mosaicml/composer"},{"category":"Machine Learning Operations","id":"machine-learning-operations--parallelization-tools--deepspeed","name":"DeepSpeed","logo":"logos/6b14333eb730fab0144979bb8029431b0c677e02dfd2944f381b7e96e31054ce.svg","subcategory":"Parallelization tools","website":"https://www.deepspeed.ai/","description":"DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.","primary_repository_url":"https://github.com/microsoft/DeepSpeed"},{"category":"Machine Learning Operations","id":"machine-learning-operations--parallelization-tools--determined","name":"Determined","logo":"logos/6b14333eb730fab0144979bb8029431b0c677e02dfd2944f381b7e96e31054ce.svg","subcategory":"Parallelization tools","website":"https://determined.ai/","description":"Determined is an open-source machine learning platform that simplifies distributed training, hyperparameter tuning, experiment tracking, and resource management. Works with PyTorch and TensorFlow.","primary_repository_url":"https://github.com/determined-ai/determined"},{"category":"Machine Learning Operations","id":"machine-learning-operations--parallelization-tools--dgl","name":"DGL","logo":"logos/6b14333eb730fab0144979bb8029431b0c677e02dfd2944f381b7e96e31054ce.svg","subcategory":"Parallelization tools","website":"https://www.dgl.ai/","description":"Python package built to ease deep learning on graph, on top of existing DL frameworks.  Fast and memory-efficient message passing primitives for training Graph Neural Networks.","primary_repository_url":"https://github.com/dmlc/dgl/"},{"category":"Machine Learning Operations","id":"machine-learning-operations--parallelization-tools--einops","name":"einops","logo":"logos/6b14333eb730fab0144979bb8029431b0c677e02dfd2944f381b7e96e31054ce.svg","subcategory":"Parallelization tools","website":"https://einops.rocks/","description":"Flexible and powerful tensor operations for readable and reliable code (for pytorch, jax, TF and others)","primary_repository_url":"https://github.com/arogozhnikov/einops"},{"category":"Machine Learning Operations","id":"machine-learning-operations--parallelization-tools--horovod","name":"Horovod","logo":"logos/6b14333eb730fab0144979bb8029431b0c677e02dfd2944f381b7e96e31054ce.svg","subcategory":"Parallelization tools","website":"http://horovod.ai/","description":"Horovod is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet","primary_repository_url":"https://github.com/horovod/horovod"},{"category":"Machine Learning Operations","id":"machine-learning-operations--parallelization-tools--ivy","name":"ivy","logo":"logos/4ac7177a12ab6aa7b56c2420367cbe3b6e1be0de2f9753d69198f5ca9a7731bb.svg","subcategory":"Parallelization tools","website":"https://ivy.dev/","description":"Convert Machine Learning Code Between Frameworks","primary_repository_url":"https://github.com/ivy-llc/ivy"},{"category":"Machine Learning Operations","id":"machine-learning-operations--parallelization-tools--octoml-profiler","name":"OctoML Profiler","logo":"logos/6b14333eb730fab0144979bb8029431b0c677e02dfd2944f381b7e96e31054ce.svg","subcategory":"Parallelization tools","website":"https://github.com/octoml/octoml-profile","description":"octoml-profile is a python library and cloud service that enables ML engineers to easily assess the performance and cost of PyTorch models on cloud hardware with state-of-the-art ML acceleration technology.","primary_repository_url":"https://github.com/octoml/octoml-profile"},{"category":"Machine Learning Operations","id":"machine-learning-operations--performance-optimization--accelerate","name":"accelerate","logo":"logos/f975c8a171af33d268543e8ec85de06980f3ddc7069f82db0645d075285c4b1d.svg","subcategory":"Performance optimization","website":"https://huggingface.co/docs/accelerate/index","description":"Accelerate is a library that enables the same PyTorch code to be run across distributed configurations","primary_repository_url":"https://github.com/huggingface/accelerate"},{"category":"Machine Learning Operations","id":"machine-learning-operations--performance-optimization--zeus","name":"Zeus","logo":"logos/88fe3408a97b0da3dfbd5328126047c69b1627ea7655a2379de2169c0dc701c2.svg","subcategory":"Performance optimization","website":"https://ml.energy/zeus/","description":"Zeus is a library for measuring the energy consumption of Deep Learning workloads and optimizing their energy consumption.","primary_repository_url":"https://github.com/ml-energy/zeus"},{"category":"Machine Learning Operations","id":"machine-learning-operations--interpretability--opencompass","name":"OpenCompass","logo":"logos/6b14333eb730fab0144979bb8029431b0c677e02dfd2944f381b7e96e31054ce.svg","subcategory":"Interpretability","website":"https://opencompass.org.cn/home","description":"OpenCompass is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets.","primary_repository_url":"https://github.com/open-compass/opencompass"},{"category":"Machine Learning Operations","id":"machine-learning-operations--experimentation--usb","name":"USB","logo":"logos/6b14333eb730fab0144979bb8029431b0c677e02dfd2944f381b7e96e31054ce.svg","subcategory":"Experimentation","website":"https://usb.readthedocs.io/en/main/","description":"Benchmark tool for developing and evaluating Semi-suprevised learning algorithms.  Includes an implementation of 14 SSL algorithms and 15 tasks for evaluation for CV, NLP, and Audio","primary_repository_url":"https://github.com/microsoft/Semi-supervised-learning"}]}