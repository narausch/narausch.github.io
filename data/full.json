{"items":[{"category":"Distributed Computing","homepage_url":"https://anomalib.readthedocs.io/en/latest/","id":"distributed-computing--training-and-evaluation--anomalib","logo":"logos/79211c70ad6c0b096a678d6642e449e908438c6ba9ea651323b55b258a1a99ac.svg","name":"Anomalib","subcategory":"Training and Evaluation","website":"https://anomalib.readthedocs.io/en/latest/","description":"An anomaly detection library comprising state-of-the-art algorithms and features such as experiment management, hyper-parameter optimization, and edge inference.","repositories":[{"url":"https://github.com/openvinotoolkit/anomalib","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://captum.ai/docs/introduction.html","id":"distributed-computing--training-and-evaluation--captum","logo":"logos/2abc1fc7558376c329b2798f7bcde761b3644e8805d84dc631370e0e76d75b8d.svg","name":"Captum","subcategory":"Training and Evaluation","website":"https://captum.ai/docs/introduction.html","description":"An open source, extensible library for model interpretability built on PyTorch.","repositories":[{"url":"https://github.com/pytorch/captum","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://www.colossalai.org/","id":"distributed-computing--training-and-evaluation--colossalai","logo":"logos/2125379104f8c98deea6e3dd3e0b2af88238792c2f41420624c1a142642c69ca.svg","name":"ColossalAI","subcategory":"Training and Evaluation","website":"https://www.colossalai.org/","description":"Tools to kickstart distributed training and inference","repositories":[{"url":"https://github.com/hpcaitech/ColossalAI","primary":true}]},{"category":"Distributed Computing","homepage_url":"http://docs.mosaicml.com/","id":"distributed-computing--training-and-evaluation--composer","logo":"logos/23206110f1d95753c27e1ebe4c63c6bc2c3b86060c4b332516cd9a3931f1900f.svg","name":"composer","subcategory":"Training and Evaluation","website":"http://docs.mosaicml.com/","description":"A open-source deep learning training library optimized for scalability and usability, integrating best practices for efficient, multi-node training","repositories":[{"url":"https://github.com/mosaicml/composer","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://www.deepspeed.ai/","id":"distributed-computing--training-and-evaluation--deepspeed","logo":"logos/6a721f2f0c7a39901db79faf3d4307b17472c558462574a3ad699666f4d0e3f3.svg","name":"DeepSpeed","subcategory":"Training and Evaluation","website":"https://www.deepspeed.ai/","description":"DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.","repositories":[{"url":"https://github.com/microsoft/DeepSpeed","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://depyf.readthedocs.io/en/latest/","id":"distributed-computing--training-and-evaluation--depyf","logo":"logos/e4a063d36b8096ad076ac1c71881f1be4ccc0a18433cd7541d08de40f2c3370f.svg","name":"Depyf","subcategory":"Training and Evaluation","website":"https://depyf.readthedocs.io/en/latest/","description":"depyf is a tool to help you understand debug and get insights into pytorch.compile","repositories":[{"url":"https://github.com/thuml/depyf","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://einops.rocks/","id":"distributed-computing--training-and-evaluation--einops","logo":"logos/b5a90edf576208a5d90039a11703e94d01d4d4941c3bb98702a13de77d0cbec3.svg","name":"einops","subcategory":"Training and Evaluation","website":"https://einops.rocks/","description":"Flexible and powerful tensor operations for readable and reliable code (for pytorch, jax, TF and others)","repositories":[{"url":"https://github.com/arogozhnikov/einops","primary":true}]},{"category":"Distributed Computing","homepage_url":"http://horovod.ai/","id":"distributed-computing--training-and-evaluation--horovod","logo":"logos/a6f46dcbeb116393f35638875cc39a90f61ebc28453af34bf89ce3185da131ae.svg","name":"Horovod","subcategory":"Training and Evaluation","website":"http://horovod.ai/","description":"Horovod is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet","repositories":[{"url":"https://github.com/horovod/horovod","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://pytorch-ignite.ai/","id":"distributed-computing--training-and-evaluation--ignite","logo":"logos/35bb1388cfcd432baba2f56afef9724cf9bbeca68724e9adcb4232272ad8309f.svg","name":"Ignite","subcategory":"Training and Evaluation","website":"https://pytorch-ignite.ai/","description":"High-level library to help with training and evaluating neural networks in PyTorch","repositories":[{"url":"https://github.com/pytorch/ignite","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://mmf.sh/","id":"distributed-computing--training-and-evaluation--mmf","logo":"logos/0c6791d31524bbcc5d00788ef39db3ff6576fdd3d3b1f8cea530d5c551e9098f.svg","name":"MMF","subcategory":"Training and Evaluation","website":"https://mmf.sh/","description":"A modular framework for vision & language multimodal research.","repositories":[{"url":"https://github.com/facebookresearch/mmf","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://onnxruntime.ai/","id":"distributed-computing--training-and-evaluation--onnx-runtime","logo":"logos/a2ab7ad7ece050a1a7e0e667813b6992c1abc606d2112dd11c8c84836b5ba522.svg","name":"ONNX runtime","subcategory":"Training and Evaluation","website":"https://onnxruntime.ai/","description":"High performance ML inferencing and training accelerator","repositories":[{"url":"https://github.com/microsoft/onnxruntime","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://opacus.ai/","id":"distributed-computing--training-and-evaluation--opacus","logo":"logos/93e7f58529785d31148daadf57a83ea2c2f8a5881b6825df426596b79b6954ad.svg","name":"Opacus","subcategory":"Training and Evaluation","website":"https://opacus.ai/","description":"Train PyTorch models with Differential Privacy","repositories":[{"url":"https://github.com/pytorch/opacus","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://opencompass.org.cn/home","id":"distributed-computing--training-and-evaluation--opencompass","logo":"logos/7a70f2cbec75cbed6adfa360674d53e5fd6536ee1b342b52588a3dbd35ef8860.svg","name":"OpenCompass","subcategory":"Training and Evaluation","website":"https://opencompass.org.cn/home","description":"OpenCompass is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets.","repositories":[{"url":"https://github.com/open-compass/opencompass","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://github.com/skorch-dev/skorch","id":"distributed-computing--training-and-evaluation--skorch","logo":"logos/5fd4c8f1c65f2f5281e64ebe6b8e82bca7b16608042672804f452b8d8f2b1d98.svg","name":"skorch","subcategory":"Training and Evaluation","website":"https://github.com/skorch-dev/skorch","description":"A scikit-learn compatible neural network library that wraps PyTorch.","repositories":[{"url":"https://github.com/skorch-dev/skorch","primary":true}]},{"category":"Distributed Computing","homepage_url":"http://tensorly.org/","id":"distributed-computing--training-and-evaluation--tensorly","logo":"logos/d4d2be7563e5a626bf144163697a53e71a99556dc4fdeb8b614bdc7a24793a6e.svg","name":"TensorLy","subcategory":"Training and Evaluation","website":"http://tensorly.org/","description":"TensorLy is a Python library that aims at making tensor learning simple and accessible. It allows to easily perform tensor decomposition, tensor learning and tensor algebra. Its backend system allows to seamlessly perform computation with NumPy, PyTorch, JAX, TensorFlow, CuPy or Paddle, and run methods at scale on CPU or GPU.","repositories":[{"url":"https://github.com/tensorly/tensorly","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://yoshitomo-matsubara.net/torchdistill/","id":"distributed-computing--training-and-evaluation--torchdistill","logo":"logos/00e6cd8399a844be633526e835a2bff2a35c27c464134204177f96b484d0b393.svg","name":"torchdistill","subcategory":"Training and Evaluation","website":"https://yoshitomo-matsubara.net/torchdistill/","description":"Offers various state-of-the-art knowledge distillation methods and enables you to design (new) experiments simply by editing a declarative yaml config file.","repositories":[{"url":"https://github.com/yoshitomo-matsubara/torchdistill","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://lightning.ai/docs/torchmetrics/","id":"distributed-computing--training-and-evaluation--torchmetrics","logo":"logos/fe7ab2ceb03b0c3b20725bb4810500052a76b2285265de910812dfa0abbbdf6c.svg","name":"TorchMetrics","subcategory":"Training and Evaluation","website":"https://lightning.ai/docs/torchmetrics/","description":"Machine learning metrics for distributed, scalable PyTorch applications.","repositories":[{"url":"https://github.com/Lightning-AI/torchmetrics","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://usb.readthedocs.io/en/main/","id":"distributed-computing--training-and-evaluation--usb","logo":"logos/ba2f979d55cfe3b448250c198b2c08437accb672f3f21600f0b3c979a399c9e7.svg","name":"USB","subcategory":"Training and Evaluation","website":"https://usb.readthedocs.io/en/main/","description":"Benchmark tool for developing and evaluating Semi-suprevised learning algorithms.  Includes an implementation of 14 SSL algorithms and 15 tasks for evaluation for CV, NLP, and Audio","repositories":[{"url":"https://github.com/microsoft/Semi-supervised-learning","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://huggingface.co/docs/accelerate/index","id":"distributed-computing--performance-optimization--accelerate","logo":"logos/f975c8a171af33d268543e8ec85de06980f3ddc7069f82db0645d075285c4b1d.svg","name":"accelerate","subcategory":"Performance optimization","website":"https://huggingface.co/docs/accelerate/index","description":"Accelerate is a library that enables the same PyTorch code to be run across distributed configurations","repositories":[{"url":"https://github.com/huggingface/accelerate","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://ensemble-pytorch.readthedocs.io/","id":"distributed-computing--performance-optimization--ensemble-pytorch","logo":"logos/1a5daa080e0d4c6242967eeac5734b744501e8d1bfe8a1f86e4305047a928ef0.svg","name":"Ensemble-Pytorch","subcategory":"Performance optimization","website":"https://ensemble-pytorch.readthedocs.io/","description":"unified ensemble framework for PyTorch to improve the performance and robustness of your ensemble based deep learning model","repositories":[{"url":"https://github.com/TorchEnsemble-Community/Ensemble-Pytorch","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://intel.github.io/intel-extension-for-pytorch/","id":"distributed-computing--performance-optimization--intel-extension-for-pytorch","logo":"logos/149058a8b3c96359ac2f000c8958b4899897602728d52d917f9335d1e0273617.svg","name":"intel-extension-for-pytorch","subcategory":"Performance optimization","website":"https://intel.github.io/intel-extension-for-pytorch/","description":"A Python extension to optimize performance on an Intel platform.","repositories":[{"url":"https://github.com/intel/intel-extension-for-pytorch","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://intel.github.io/neural-compressor/latest/docs/source/Welcome.html","id":"distributed-computing--performance-optimization--neural-compressor","logo":"logos/ba40986b1563b5634522df1bb286e54e543fea3a4ce7e5d0f72c2de633c074f5.svg","name":"neural-compressor","subcategory":"Performance optimization","website":"https://intel.github.io/neural-compressor/latest/docs/source/Welcome.html","description":"An open-source Python library supporting popular model compression techniques on all deep learning frameworks.","repositories":[{"url":"https://github.com/intel/neural-compressor","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://optuna.org/","id":"distributed-computing--performance-optimization--optuna","logo":"logos/221ccf5311fc9739ea42133e7727c4e1e3bbdb761fee27e5f71434e93ea35740.svg","name":"Optuna","subcategory":"Performance optimization","website":"https://optuna.org/","description":"Optuna is an automatic hyperparameter optimization software framework, particularly designed for machine learning.","repositories":[{"url":"https://github.com/optuna/optuna","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/","id":"distributed-computing--performance-optimization--poptorch","logo":"logos/941ac64f6b2ec287a2dfc558c637747c9af0d2acdcf5e6148bdbfc5e2f8a81d5.svg","name":"PopTorch","subcategory":"Performance optimization","website":"https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/","description":"PopTorch is a set of extensions for PyTorch enabling models to be trained, evaluated and used on the Graphcore IPU.","repositories":[{"url":"https://github.com/graphcore/poptorch","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://lightning.ai/","id":"distributed-computing--performance-optimization--pytorch-lightning","logo":"logos/9ea7a73b721cef9519fd2ac3cc48b9dd167e210bda4ce34ae8c8984d9ad28ebd.svg","name":"PyTorch Lightning","subcategory":"Performance optimization","website":"https://lightning.ai/","description":"Pretrain, finetune and deploy AI models on multiple GPUs, TPUs with zero code changes.","repositories":[{"url":"https://github.com/Lightning-AI/pytorch-lightning","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://github.com/ray-project/ray","id":"distributed-computing--performance-optimization--ray","logo":"logos/3975c0f455d00dfab6b5c78281eb7c5dd6ffcf105bcc8c78764eb09a5ed534a6.svg","name":"Ray","subcategory":"Performance optimization","website":"https://github.com/ray-project/ray","description":"Ray is a unified framework for scaling AI and Python applications. Ray consists of a core distributed runtime and a set of AI Libraries for accelerating ML workloads.","repositories":[{"url":"https://github.com/ray-project/ray","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://pytorch.org/TensorRT/","id":"distributed-computing--performance-optimization--torch-tensorrt","logo":"logos/07dbeb39c385db2b246f1fb02d2534f65455facf03f6249afc3eaf34baaddfc1.svg","name":"Torch-TensorRT","subcategory":"Performance optimization","website":"https://pytorch.org/TensorRT/","description":"Torch-TensorRT is a inference compiler for PyTorch, targeting NVIDIA GPUs via NVIDIA’s TensorRT Deep Learning Optimizer and Runtime.","repositories":[{"url":"https://github.com/RizhaoCai/PyTorch_ONNX_TensorRT","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://torchopt.readthedocs.io/en/latest/","id":"distributed-computing--performance-optimization--torchopt","logo":"logos/fa7428c96683f978432a500f84b389bd2f5a07cb9738885282a728a9015c5cfd.svg","name":"Torchopt","subcategory":"Performance optimization","website":"https://torchopt.readthedocs.io/en/latest/","description":"An efficient library for differentiable optimization built upon PyTorch","repositories":[{"url":"https://github.com/metaopt/TorchOpt","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://ml.energy/zeus/","id":"distributed-computing--performance-optimization--zeus","logo":"logos/88fe3408a97b0da3dfbd5328126047c69b1627ea7655a2379de2169c0dc701c2.svg","name":"Zeus","subcategory":"Performance optimization","website":"https://ml.energy/zeus/","description":"Zeus is a library for measuring the energy consumption of Deep Learning workloads and optimizing their energy consumption.","repositories":[{"url":"https://github.com/ml-energy/zeus","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://clear.ml/","id":"distributed-computing--parallelization-tools--clear-ml","logo":"logos/b8f9b0d3ee7df42d688ddfaf95b3177f256d68521167ac27b601778e339fbedc.svg","name":"Clear ML","subcategory":"Parallelization tools","website":"https://clear.ml/","description":"Suite of tools to streamline your AI workflow.","repositories":[{"url":"https://github.com/allegroai/clearml","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://determined.ai/","id":"distributed-computing--parallelization-tools--determined","logo":"logos/6f06ce54ac2345f4d76475807a8d81d20d4f6d8f1f017ac591fb22f312ef329c.svg","name":"Determined","subcategory":"Parallelization tools","website":"https://determined.ai/","description":"Determined is an open-source machine learning platform that simplifies distributed training, hyperparameter tuning, experiment tracking, and resource management. Works with PyTorch and TensorFlow.","repositories":[{"url":"https://github.com/determined-ai/determined","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://www.dgl.ai/","id":"distributed-computing--parallelization-tools--dgl","logo":"logos/8bc26a2c13a583b1695caeee24b08ead02adb0d16645e0d2763ea37305fae388.svg","name":"DGL","subcategory":"Parallelization tools","website":"https://www.dgl.ai/","description":"Python package built to ease deep learning on graph, on top of existing DL frameworks.  Fast and memory-efficient message passing primitives for training Graph Neural Networks.","repositories":[{"url":"https://github.com/dmlc/dgl/","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://docs.fast.ai/","id":"distributed-computing--parallelization-tools--fastai","logo":"logos/9b1d9cefe662d9c4a595cbe44fddc8c2d31a2390f6ac3ac0ae025a8c878a53ce.svg","name":"fastai","subcategory":"Parallelization tools","website":"https://docs.fast.ai/","description":"fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches","repositories":[{"url":"https://github.com/fastai/fastai","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://ivy.dev/","id":"distributed-computing--parallelization-tools--ivy","logo":"logos/4ac7177a12ab6aa7b56c2420367cbe3b6e1be0de2f9753d69198f5ca9a7731bb.svg","name":"ivy","subcategory":"Parallelization tools","website":"https://ivy.dev/","description":"Convert Machine Learning Code Between Frameworks","repositories":[{"url":"https://github.com/ivy-llc/ivy","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://github.com/octoml/octoml-profile","id":"distributed-computing--parallelization-tools--octoml-profiler","logo":"logos/6a0430bf99ada8d6b9a2f7c296d8719bd6d5081f40036783c1ee51c58ae73217.svg","name":"OctoML Profiler","subcategory":"Parallelization tools","website":"https://github.com/octoml/octoml-profile","description":"octoml-profile is a python library and cloud service that enables ML engineers to easily assess the performance and cost of PyTorch models on cloud hardware with state-of-the-art ML acceleration technology.","repositories":[{"url":"https://github.com/octoml/octoml-profile","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://www.openmined.org/","id":"distributed-computing--parallelization-tools--pysyft","logo":"logos/ddcdd70695dcc0780072851c60375522b8a616c35ffdec80717cf32b87d21310.svg","name":"PySyft","subcategory":"Parallelization tools","website":"https://www.openmined.org/","description":"Perform data science on data that remains in someone else's server","repositories":[{"url":"https://github.com/OpenMined/PySyft","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://flower.ai/","id":"distributed-computing--federated-learning--flower","logo":"logos/af4acf3f0922e8bb18cd7439136d299b7c8ddd7c5b8e7574bb31c17c6b4450b1.svg","name":"Flower","subcategory":"Federated learning","website":"https://flower.ai/","description":"A unified approach to federated learning, analytics, and evaluation. Federate any workload, any ML framework, and any programming language","repositories":[{"url":"https://github.com/adap/flower","primary":true}]},{"category":"Distributed Computing","homepage_url":"https://docs.substra.org/","id":"distributed-computing--federated-learning--substra","logo":"logos/57e63c3a4288f965a164da315553b98b67b369bbee4e6d9a24cdfd6cb43bc380.svg","name":"Substra","subcategory":"Federated learning","website":"https://docs.substra.org/","description":"Substra is used to run complex federated learning experiments at scale.","repositories":[{"url":"https://github.com/Substra","primary":true}]},{"category":"Model","homepage_url":"https://albumentations.ai/docs/","id":"model--computer-vision--albumentations","logo":"logos/9c283e8d47d4c3f87139e047313bbb92c6f038a28d7d1ceea7378542b33b9dd5.svg","name":"Albumentations","subcategory":"Computer vision","website":"https://albumentations.ai/docs/","description":"a Python library for image augmentation used in deep learning and computer vision tasks to increase the quality of trained models. The purpose of image augmentation is to create new training samples from the existing data.","repositories":[{"url":"https://github.com/albumentations-team/albumentations","primary":true}]},{"category":"Model","homepage_url":"https://clinicadl.readthedocs.io/en/latest/","id":"model--computer-vision--clinica-dl","logo":"logos/0e35348df86096d30232c0f852e0821acb387f280097ad52f6b298ee03147ee8.svg","name":"Clinica DL","subcategory":"Computer vision","website":"https://clinicadl.readthedocs.io/en/latest/","description":"open-source deep learning software for reproducible neuroimaging processing. It can be seen as the deep learning extension of Clinica, an open-source Python library for neuroimaging preprocessing and analysis.","repositories":[{"url":"https://github.com/aramis-lab/clinicadl","primary":true}]},{"category":"Model","homepage_url":"https://www.nature.com/articles/s44172-023-00066-3","id":"model--computer-vision--gandlf","logo":"logos/2c684fbc52871399018ed1bbd4eb4558cf380b37f789128ab453063f072a1377.svg","name":"GaNDLF","subcategory":"Computer vision","website":"https://www.nature.com/articles/s44172-023-00066-3","description":"The Generally Nuanced Deep Learning Framework (GaNDLF) for image segmentation and classification, especially in the biomedical field.","repositories":[{"url":"https://github.com/mlcommons/gandlf","primary":true}]},{"category":"Model","homepage_url":"https://kornia.github.io/","id":"model--computer-vision--kornia","logo":"logos/68d50512b8d058f5ae4c92b0fdb1a54132e0b208cb573c1b84bb19e7a2cabd4c.svg","name":"Kornia","subcategory":"Computer vision","website":"https://kornia.github.io/","description":"Kornia is a geometric computer vision Library for spatial AI library that allows classical computer vision to be integrated into deep learning models.","repositories":[{"url":"https://github.com/kornia/kornia","primary":true}]},{"category":"Model","homepage_url":"https://docs.lightly.ai/self-supervised-learning/","id":"model--computer-vision--lightly","logo":"logos/5135c80fa8aeb01b5a93eb51f1c869d3e920e89759d25f423e0edb513df1fd02.svg","name":"Lightly","subcategory":"Computer vision","website":"https://docs.lightly.ai/self-supervised-learning/","description":"LightlySSL is a computer vision framework for self-supervised learning.","repositories":[{"url":"https://github.com/lightly-ai/lightly","primary":true}]},{"category":"Model","homepage_url":"https://openmmlab.com/","id":"model--computer-vision--openmmlab","logo":"logos/4efdc7f99d6658760637db639f854554798b6fac64d661903c68e7728e5014ba.svg","name":"OpenMMLab","subcategory":"Computer vision","website":"https://openmmlab.com/","description":"Open-source computer vision algorithms and models.","repositories":[{"url":"https://github.com/open-mmlab","primary":true}]},{"category":"Model","homepage_url":"https://pytorch3d.org/","id":"model--computer-vision--pytorch3d","logo":"logos/88318438fc9c2bbc4989daf11182ed9ec9e685c4f9f97317d978d87f732f9e96.svg","name":"PyTorch3D","subcategory":"Computer vision","website":"https://pytorch3d.org/","description":"PyTorch3D is a library of reusable components for deep learning with 3D data","repositories":[{"url":"https://github.com/facebookresearch/pytorch3d","primary":true}]},{"category":"Model","homepage_url":"https://joeynmt.readthedocs.io/en/latest/#","id":"model--specialized--joeynmt","logo":"logos/817179366550e656ee07a69f74369f9b49b23e815c2d4c3d5a092fbf4318dbc9.svg","name":"joeynmt","subcategory":"Specialized","website":"https://joeynmt.readthedocs.io/en/latest/#","description":"JoeyNMT is a minimalist neural machine translation toolkit for educational purposes.","repositories":[{"url":"https://github.com/joeynmt","primary":true}]},{"category":"Model","homepage_url":"https://pypose.org/","id":"model--specialized--pypose","logo":"logos/8513a8257efd437369eb631ace0e7514cfdce3e6297154043bc263c67f49d128.svg","name":"PyPose","subcategory":"Specialized","website":"https://pypose.org/","description":"PyPose is a library for Robot Learning with Physics-based Optimization","repositories":[{"url":"https://github.com/pypose/pypose","primary":true}]},{"category":"Model","homepage_url":"https://pypots.com/","id":"model--specialized--pypots","logo":"logos/9b443ae59bd33bdee86bbe1d3190c727ce938845d8696ac8e76bd7c662c822a2.svg","name":"PyPOTS","subcategory":"Specialized","website":"https://pypots.com/","description":"a Python toolbox for machine learning on Partially-Observed Time Series","repositories":[{"url":"https://github.com/WenjieDu/PyPOTS","primary":true}]},{"category":"Model","homepage_url":"https://pyg.org/","id":"model--specialized--pytorch-geometric","logo":"logos/5bf81a10e91e5b5336f31c52500e47e02dc3c860f3d66c7b4936161107dc12c9.svg","name":"PyTorch Geometric","subcategory":"Specialized","website":"https://pyg.org/","description":"Graph Neural Network Library for PyTorch","repositories":[{"url":"https://github.com/pyg-team/pytorch_geometric","primary":true}]},{"category":"Model","homepage_url":"https://kevinmusgrave.github.io/pytorch-metric-learning/","id":"model--specialized--pytorch-metric-learning","logo":"logos/64fe0aa1a6facd5730cee30d3904885e90f56c6cc79d9f9edda241ecf4585ff7.svg","name":"PyTorch Metric Learning","subcategory":"Specialized","website":"https://kevinmusgrave.github.io/pytorch-metric-learning/","description":"Modular, flexible, and extensible library for deep metric learning.","repositories":[{"url":"https://github.com/KevinMusgrave/pytorch-metric-learning","primary":true}]},{"category":"Model","homepage_url":"https://ibm.github.io/simulai/","id":"model--specialized--simulai","logo":"logos/52d2378814907baeac4813eba9000d2ac5fb8a804f9c7a621b96003bdc3738e2.svg","name":"SimulAI","subcategory":"Specialized","website":"https://ibm.github.io/simulai/","description":"A toolkit with data-driven pipelines for physics-informed machine learning.","repositories":[{"url":"https://github.com/IBM/simulai","primary":true}]},{"category":"Model","homepage_url":"https://baal.readthedocs.io/","id":"model--probabilistic-models--baal","logo":"logos/e52fe477062933115c9eee93722f40f2dba311e6935fb12b5bf490fc94c26eb5.svg","name":"baal","subcategory":"Probabilistic Models","website":"https://baal.readthedocs.io/","description":"Baal is a Bayesian active learning library. Provides methods to do posterior distribution sampling in order to maximize the efficiency of labelling during active learning. Our library is suitable for research and industrial applications.","repositories":[{"url":"https://github.com/baal-org/baal","primary":true}]},{"category":"Model","homepage_url":"https://botorch.org/","id":"model--probabilistic-models--botorch","logo":"logos/bf6001cce117af4ae13495875da21ba11ba34f5d42b525ce555f61452ad9fc6d.svg","name":"BoTorch","subcategory":"Probabilistic Models","website":"https://botorch.org/","description":"A Framework for Efficient Monte-Carlo Bayesian Optimization","repositories":[{"url":"https://github.com/pytorch/botorch","primary":true}]},{"category":"Model","homepage_url":"https://arxiv.org/abs/1809.11165","id":"model--probabilistic-models--gpytorch","logo":"logos/edd7c89043cddc740dd6ccd3746aee9f57a590b76e93440eff93fb7272c3f4ce.svg","name":"GPyTorch","subcategory":"Probabilistic Models","website":"https://arxiv.org/abs/1809.11165","description":"GPyTorch is a Gaussian process library implemented using PyTorch. GPyTorch is designed for creating scalable, flexible, and modular Gaussian process models with ease","repositories":[{"url":"https://github.com/cornellius-gp/gpytorch","primary":true}]},{"category":"Model","homepage_url":"https://pomegranate.readthedocs.io/en/latest/","id":"model--probabilistic-models--pomegranate","logo":"logos/ebf8effc430934c78a17464087fe36856c0dfe2c390f3e278beac637efb264e0.svg","name":"Pomegranate","subcategory":"Probabilistic Models","website":"https://pomegranate.readthedocs.io/en/latest/","description":"pomegranate is a Python package that implements fast and flexible probabilistic models ranging from individual probability distributions to compositional models such as Bayesian networks and hidden Markov models","repositories":[{"url":"https://github.com/jmschrei/pomegranate","primary":true}]},{"category":"Model","homepage_url":"https://pyro.ai/","id":"model--probabilistic-models--pyro","logo":"logos/ed7e2a4d5d7f216c73dc8d10febb6720c12b706bd262296605f82b5f01801d60.svg","name":"Pyro","subcategory":"Probabilistic Models","website":"https://pyro.ai/","description":"Deep universal probabilistic programming with Python and PyTorch","repositories":[{"url":"https://github.com/pyro-ppl/pyro","primary":true}]},{"category":"Model","homepage_url":"https://pytorch.org/ecosystem/","id":"model--biomedical--fusemedml","logo":"logos/bed2d7b1ea133092432cc28a1d20d3314098a2c30624894f1bad0ed7162fa03d.svg","name":"FuseMedML","subcategory":"Biomedical","website":"https://pytorch.org/ecosystem/","description":"A python framework accelerating ML based discovery in the medical field by encouraging code reuse","repositories":[{"url":"https://github.com/BiomedSciAI/fuse-med-ml","primary":true}]},{"category":"Model","homepage_url":"https://monai.io/","id":"model--biomedical--monai","logo":"logos/05c4cdff595fa70e0ca8175384c2fbe4efc7c321437d8fd14bd6f13a9671fb74.svg","name":"MONAI","subcategory":"Biomedical","website":"https://monai.io/","description":"AI Toolkit for Healthcare Imaging","repositories":[{"url":"https://github.com/Project-MONAI","primary":true}]},{"category":"Model","homepage_url":"https://warwick.ac.uk/fac/cross_fac/tia/","id":"model--biomedical--tiatoolbox","logo":"logos/ba4859ff6d65b65bc3b5e1a48fdffcb34c3d0ff8435c11eb1f1aac0120c1224d.svg","name":"TIAToolbox","subcategory":"Biomedical","website":"https://warwick.ac.uk/fac/cross_fac/tia/","description":"TIAToolbox is a computational pathology toolbox for pathology image analysis.","repositories":[{"url":"https://github.com/TissueImageAnalytics/tiatoolbox","primary":true}]},{"category":"Model","homepage_url":"http://www.torchio.org/","id":"model--biomedical--torchio","logo":"logos/3f53485d82e837e49ad8c2f5b2ca860ac321809c9d7a50f6f4029c49911a158f.svg","name":"TorchIO","subcategory":"Biomedical","website":"http://www.torchio.org/","description":"Medical imaging toolkit for deep learning","repositories":[{"url":"https://github.com/fepegar/torchio","primary":true}]},{"category":"Model","homepage_url":"https://ludwig.ai/latest/","id":"model--transfer-learning--ludwig","logo":"logos/6e299a3f1f6df294a97064d136dd13a8078ec5ccc3d9cfdf4f3f57faf17e4b3b.svg","name":"ludwig","subcategory":"Transfer Learning","website":"https://ludwig.ai/latest/","description":"Ludwig is a low-code framework for building custom AI models like LLMs and other deep neural networks.","repositories":[{"url":"https://github.com/ludwig-ai/ludwig","primary":true}]},{"category":"Model","homepage_url":"https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html","id":"model--transfer-learning--nemo","logo":"logos/28338dbf8ea96d2f14e1e737ecab8f55ada4616e445a10a89f0cb2c019ee8f14.svg","name":"NeMo","subcategory":"Transfer Learning","website":"https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html","description":"A scalable generative AI framework built for researchers and developers working on Large Language Models, Multimodal, and Speech AI (Automatic Speech Recognition and Text-to-Speech)","repositories":[{"url":"https://github.com/NVIDIA/NeMo","primary":true}]},{"category":"Model","homepage_url":"https://pykale.github.io/","id":"model--transfer-learning--pykale","logo":"logos/1514ccbb316a3ae5a772df0cb382bd6917c12793cc8174f0699d4fb19d1acec0.svg","name":"PyKale","subcategory":"Transfer Learning","website":"https://pykale.github.io/","description":"PyKale has a unified pipeline-based API and focuses on multimodal learning and transfer learning for graphs, images, and videos at the moment, with supporting models on deep learning and dimensionality reduction.","repositories":[{"url":"https://github.com/pykale/pykale","primary":true}]},{"category":"Model","homepage_url":"https://huggingface.co/docs/diffusers/index","id":"model--pretrained-models--diffusers","logo":"logos/ffc8bf3d4d9c6e89044e907ea8b49195426ef764da054041f80845be8605c48e.svg","name":"Diffusers","subcategory":"Pretrained Models","website":"https://huggingface.co/docs/diffusers/index","description":"Pretrained diffusion models for generating images, audio, and even 3D structures of molecules. Whether you are looking for a simple inference solution or want to train your own diffusion model, Diffusers is a modular toolbox that supports both","repositories":[{"url":"https://github.com/huggingface/diffusers","primary":true}]},{"category":"Model","homepage_url":"https://stable-baselines3.readthedocs.io/","id":"model--pretrained-models--stable-baselines3","logo":"logos/a0f8f03828e020f203be7c6c0e19ccab88e2fe89feeaad3d517c79033bae9edf.svg","name":"Stable Baselines3","subcategory":"Pretrained Models","website":"https://stable-baselines3.readthedocs.io/","description":"Stable Baselines3 (SB3) is a set of implementations of reinforcement learning algorithms","repositories":[{"url":"https://github.com/DLR-RM/stable-baselines3","primary":true}]},{"category":"Model","homepage_url":"https://huggingface.co/transformers","id":"model--pretrained-models--transformers","logo":"logos/22ee2a64b64ec10d3f8665a2c99fe71389da44d177ce9688632c462e8627224b.svg","name":"Transformers","subcategory":"Pretrained Models","website":"https://huggingface.co/transformers","description":"Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.","repositories":[{"url":"https://github.com/huggingface/transformers","primary":true}]},{"category":"Model","homepage_url":"https://allenai.org/allennlp","id":"model--natural-language-processing--allennlp","logo":"logos/43d3a869c90be770813540f0fd05114f0250a9fb796e52ed7f7ceb33772ad2ef.svg","name":"AllenNLP","subcategory":"Natural Language Processing","website":"https://allenai.org/allennlp","description":"An NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks.","repositories":[{"url":"https://github.com/allenai/allennlp","primary":true}]},{"category":"Model","homepage_url":"https://github.com/flairNLP/flair","id":"model--natural-language-processing--flair","logo":"logos/79bb5140f6e438d44b09dbd2bde4ba675f11bb1e19b84e74b0ada9b16c0b034a.svg","name":"Flair","subcategory":"Natural Language Processing","website":"https://github.com/flairNLP/flair","description":"Flair allows you to apply our state-of-the-art natural language processing (NLP) models to your text, such as named entity recognition (NER), sentiment analysis, part-of-speech tagging (PoS), special support for biomedical texts, sense disambiguation and classification, with support for a rapidly growing number of languages","repositories":[{"url":"https://github.com/flairNLP/flair","primary":true}]},{"category":"Model","homepage_url":"http://avalanche.continualai.org/","id":"model--continuous-learning--avalanche","logo":"logos/6db724b646af4bb6a96bf1e939a4018ee5f01db33e92af69a611275266ba90f5.svg","name":"avalanche","subcategory":"Continuous Learning","website":"http://avalanche.continualai.org/","description":"Avalanche is an End-to-End Continual Learning Library based on PyTorch, for fast prototyping, training, and reproducible evaluation of continual learning algorithms.","repositories":[{"url":"https://github.com/ContinualAI/avalanche","primary":true}]},{"category":"Model","homepage_url":"https://renate.readthedocs.io/en/latest/","id":"model--continuous-learning--renate","logo":"logos/e9fb21ed75b6d1f586d07a501eb6f349489335f0bbc79c436f625b5f0e753577.svg","name":"Renate","subcategory":"Continuous Learning","website":"https://renate.readthedocs.io/en/latest/","description":"Renate is a Python package for automatic retraining of neural networks models. It uses advanced Continual Learning and Lifelong Learning algorithms to achieve this purpose.","repositories":[{"url":"https://github.com/awslabs/renate","primary":true}]},{"category":"Model","homepage_url":"https://pennylane.ai/","id":"model--quantum-computing--pennylane","logo":"logos/2d8e7a169283e296f1d72aad881717481147608ecb440ecb9b92b3c078ce197f.svg","name":"PennyLane","subcategory":"Quantum Computing","website":"https://pennylane.ai/","description":"PennyLane is a cross-platform Python library for quantum computing, quantum machine learning, and quantum chemistry. Train a quantum computer the same way as a neural network.","repositories":[{"url":"https://github.com/PennyLaneAI/pennylane","primary":true}]},{"category":"Model","homepage_url":"https://hanruiwanghw.wixsite.com/torchquantum","id":"model--quantum-computing--torchquantum","logo":"logos/eba8a1f3cf2a73d23a295af0b6e67dcb61560ca1630acae2f929fea8cd863b90.svg","name":"TorchQuantum","subcategory":"Quantum Computing","website":"https://hanruiwanghw.wixsite.com/torchquantum","description":"A framework for Quantum Classical Simulation, Quantum Machine Learning, Quantum Neural Networks, Parameterized Quantum Circuits with support for easy deployments on real quantum computers.","repositories":[{"url":"https://github.com/mit-han-lab/torchquantum","primary":true}]},{"category":"Model","homepage_url":"https://docs.rastervision.io/","id":"model--geospatial--raster-vision","logo":"logos/7f48d1f43ed40f3c3dda9f013919d00e801e756dabb5def767474c58f08cf117.svg","name":"raster-vision","subcategory":"Geospatial","website":"https://docs.rastervision.io/","description":"Raster Vision is an open source library and framework for Python developers building computer vision models on satellite, aerial, and other large imagery sets (including oblique drone imagery). There is built-in support for chip classification, object detection, and semantic segmentation using PyTorch.","repositories":[{"url":"https://github.com/azavea/raster-vision","primary":true}]},{"category":"Model","homepage_url":"https://www.osgeo.org/projects/torchgeo/","id":"model--geospatial--torchgeo","logo":"logos/0f021d5c7b0d805439d23e941b0a743d16b7cf89fa11b5cc9c19a53d44549420.svg","name":"torchgeo","subcategory":"Geospatial","website":"https://www.osgeo.org/projects/torchgeo/","description":"TorchGeo is a toolkit containing datasets, samplers, transforms, and pre-trained models for geospatial data.","repositories":[{"url":"https://github.com/microsoft/torchgeo","primary":true}]}]}