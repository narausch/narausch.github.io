{"category":{"name":"Hardware Optimization","normalized_name":"hardware-optimization","subcategories":[{"name":"Performance optimization","normalized_name":"performance-optimization"}]},"foundation":"PyTorch","items":[{"category":"Hardware Optimization","id":"hardware-optimization--performance-optimization--poptorch","name":"PopTorch","logo":"logos/6b14333eb730fab0144979bb8029431b0c677e02dfd2944f381b7e96e31054ce.svg","subcategory":"Performance optimization","website":"https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/","description":"PopTorch is a set of extensions for PyTorch enabling models to be trained, evaluated and used on the Graphcore IPU.","primary_repository_url":"https://github.com/graphcore/poptorch"},{"category":"Hardware Optimization","id":"hardware-optimization--performance-optimization--pytorch-lightning","name":"PyTorch Lightning","logo":"logos/9ea7a73b721cef9519fd2ac3cc48b9dd167e210bda4ce34ae8c8984d9ad28ebd.svg","subcategory":"Performance optimization","website":"https://lightning.ai/","description":"Pretrain, finetune and deploy AI models on multiple GPUs, TPUs with zero code changes.","primary_repository_url":"https://github.com/Lightning-AI/pytorch-lightning"},{"category":"Hardware Optimization","id":"hardware-optimization--performance-optimization--torch-tensorrt","name":"Torch-TensorRT","logo":"logos/6b14333eb730fab0144979bb8029431b0c677e02dfd2944f381b7e96e31054ce.svg","subcategory":"Performance optimization","website":"https://pytorch.org/TensorRT/","description":"Torch-TensorRT is a inference compiler for PyTorch, targeting NVIDIA GPUs via NVIDIAâ€™s TensorRT Deep Learning Optimizer and Runtime.","primary_repository_url":"https://github.com/RizhaoCai/PyTorch_ONNX_TensorRT"}]}