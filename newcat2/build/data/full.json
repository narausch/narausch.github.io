{"items":[{"category":"Modeling","homepage_url":"https://huggingface.co/docs/accelerate/index","id":"modeling--computer-vision--accelerate","logo":"logos/f975c8a171af33d268543e8ec85de06980f3ddc7069f82db0645d075285c4b1d.svg","name":"accelerate","subcategory":"Computer Vision","website":"https://huggingface.co/docs/accelerate/index","description":"Accelerate is a library that enables the same PyTorch code to be run across distributed configurations","repositories":[{"url":"https://github.com/huggingface/accelerate","primary":true}]},{"category":"Modeling","homepage_url":"https://albumentations.ai/docs/","id":"modeling--computer-vision--albumentations","logo":"logos/9c283e8d47d4c3f87139e047313bbb92c6f038a28d7d1ceea7378542b33b9dd5.svg","name":"Albumentations","subcategory":"Computer Vision","website":"https://albumentations.ai/docs/","description":"a Python library for image augmentation used in deep learning and computer vision tasks to increase the quality of trained models. The purpose of image augmentation is to create new training samples from the existing data.","repositories":[{"url":"https://github.com/albumentations-team/albumentations","primary":true}]},{"category":"Modeling","homepage_url":"https://anomalib.readthedocs.io/en/latest/","id":"modeling--computer-vision--anomalib","logo":"logos/79211c70ad6c0b096a678d6642e449e908438c6ba9ea651323b55b258a1a99ac.svg","name":"Anomalib","subcategory":"Computer Vision","website":"https://anomalib.readthedocs.io/en/latest/","description":"An anomaly detection library comprising state-of-the-art algorithms and features such as experiment management, hyper-parameter optimization, and edge inference.","repositories":[{"url":"https://github.com/openvinotoolkit/anomalib","primary":true}]},{"category":"Modeling","homepage_url":"https://detectron2.readthedocs.io/en/latest/","id":"modeling--computer-vision--detectron2","logo":"logos/09c4e847ff560f506f21bd599257ed2204e309e54cfd66f008f2d2c40a46244b.svg","name":"Detectron2","subcategory":"Computer Vision","website":"https://detectron2.readthedocs.io/en/latest/","description":"is a platform for object detection, segmentation and other visual recognition tasks.","repositories":[{"url":"https://github.com/facebookresearch/detectron2","primary":true}]},{"category":"Modeling","homepage_url":"https://kornia.github.io/","id":"modeling--computer-vision--kornia","logo":"logos/68d50512b8d058f5ae4c92b0fdb1a54132e0b208cb573c1b84bb19e7a2cabd4c.svg","name":"Kornia","subcategory":"Computer Vision","website":"https://kornia.github.io/","description":"Kornia is a geometric computer vision Library for spatial AI library that allows classical computer vision to be integrated into deep learning models.","repositories":[{"url":"https://github.com/kornia/kornia","primary":true}]},{"category":"Modeling","homepage_url":"https://docs.lightly.ai/self-supervised-learning/","id":"modeling--computer-vision--lightly","logo":"logos/5135c80fa8aeb01b5a93eb51f1c869d3e920e89759d25f423e0edb513df1fd02.svg","name":"Lightly","subcategory":"Computer Vision","website":"https://docs.lightly.ai/self-supervised-learning/","description":"LightlySSL is a computer vision framework for self-supervised learning.","repositories":[{"url":"https://github.com/lightly-ai/lightly","primary":true}]},{"category":"Modeling","homepage_url":"https://mmagic.readthedocs.io/en/latest/","id":"modeling--computer-vision--mmediting","logo":"logos/2dd6eb493139d0728db74c27c9fd20e49fc83dd40a459aa1dfee080548d9651b.svg","name":"MMEditing","subcategory":"Computer Vision","website":"https://mmagic.readthedocs.io/en/latest/","description":"Image and Video Restoration, Editing and Generation Toolbox","repositories":[{"url":"https://github.com/open-mmlab/mmediting","primary":true}]},{"category":"Modeling","homepage_url":"https://openmmlab.com/","id":"modeling--computer-vision--openmmlab","logo":"logos/4efdc7f99d6658760637db639f854554798b6fac64d661903c68e7728e5014ba.svg","name":"OpenMMLab","subcategory":"Computer Vision","website":"https://openmmlab.com/","description":"Open-source computer vision algorithms and models.","repositories":[{"url":"https://github.com/open-mmlab","primary":true}]},{"category":"Modeling","homepage_url":"https://github.com/pystiche/pystiche","id":"modeling--computer-vision--pystiche","logo":"logos/b024259eacdf1948a9a6dcc2b94a9d67df1e249789ac8d44c6d822e4e7d0cdae.svg","name":"pystiche","subcategory":"Computer Vision","website":"https://github.com/pystiche/pystiche","description":"Framework for Neural Style Transfer (NST) built upon PyTorch","repositories":[{"url":"https://github.com/pystiche/pystiche","primary":true}]},{"category":"Modeling","homepage_url":"https://docs.rastervision.io/","id":"modeling--computer-vision--raster-vision","logo":"logos/7f48d1f43ed40f3c3dda9f013919d00e801e756dabb5def767474c58f08cf117.svg","name":"raster-vision","subcategory":"Computer Vision","website":"https://docs.rastervision.io/","description":"Raster Vision is an open source library and framework for Python developers building computer vision models on satellite, aerial, and other large imagery sets (including oblique drone imagery). There is built-in support for chip classification, object detection, and semantic segmentation using PyTorch.","repositories":[{"url":"https://github.com/azavea/raster-vision","primary":true}]},{"category":"Modeling","homepage_url":"https://vissl.ai/","id":"modeling--computer-vision--vissl","logo":"logos/016493ec5173a2af3effb4dd26c934658094910366ce5258a8b1534a7d6e5027.svg","name":"VISSL","subcategory":"Computer Vision","website":"https://vissl.ai/","description":"A library for state-of-the-art self-supervised learning from images","repositories":[{"url":"https://github.com/facebookresearch/vissl/graphs/commit-activity","primary":true}]},{"category":"Modeling","homepage_url":"https://allenai.org/allennlp","id":"modeling--language--allennlp","logo":"logos/43d3a869c90be770813540f0fd05114f0250a9fb796e52ed7f7ceb33772ad2ef.svg","name":"AllenNLP","subcategory":"Language","website":"https://allenai.org/allennlp","description":"An NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks.","repositories":[{"url":"https://github.com/allenai/allennlp","primary":true}]},{"category":"Modeling","homepage_url":"https://www.colossalai.org/","id":"modeling--language--colossal-llama-2","logo":"logos/9dad1dc0f5e62ccaae15a7b3d9df96926275a1b075aad0107a87dee756bcf9be.svg","name":"Colossal-LLaMA-2","subcategory":"Language","website":"https://www.colossalai.org/","description":"This project is no longer available","repositories":[{"url":"https://github.com/hpcaitech/ColossalAI/tree/main/applications/Colossal-LLaMA-2","primary":true}]},{"category":"Modeling","homepage_url":"https://github.com/flairNLP/flair","id":"modeling--language--flair","logo":"logos/79bb5140f6e438d44b09dbd2bde4ba675f11bb1e19b84e74b0ada9b16c0b034a.svg","name":"Flair","subcategory":"Language","website":"https://github.com/flairNLP/flair","description":"Flair allows you to apply our state-of-the-art natural language processing (NLP) models to your text, such as named entity recognition (NER), sentiment analysis, part-of-speech tagging (PoS), special support for biomedical texts, sense disambiguation and classification, with support for a rapidly growing number of languages","repositories":[{"url":"https://github.com/flairNLP/flair","primary":true}]},{"category":"Modeling","homepage_url":"https://joeynmt.readthedocs.io/en/latest/#","id":"modeling--language--joeynmt","logo":"logos/817179366550e656ee07a69f74369f9b49b23e815c2d4c3d5a092fbf4318dbc9.svg","name":"joeynmt","subcategory":"Language","website":"https://joeynmt.readthedocs.io/en/latest/#","description":"JoeyNMT is a minimalist neural machine translation toolkit for educational purposes.","repositories":[{"url":"https://github.com/joeynmt","primary":true}]},{"category":"Modeling","homepage_url":"https://opencompass.org.cn/home","id":"modeling--language--opencompass","logo":"logos/7a70f2cbec75cbed6adfa360674d53e5fd6536ee1b342b52588a3dbd35ef8860.svg","name":"OpenCompass","subcategory":"Language","website":"https://opencompass.org.cn/home","description":"OpenCompass is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets.","repositories":[{"url":"https://github.com/open-compass/opencompass","primary":true}]},{"category":"Modeling","homepage_url":"https://parl.ai/","id":"modeling--language--pariai","logo":"logos/0fd85ffd8df76e3a4ece780593d9f95b8c193bf33cf97c16955e93ca59b757fd.svg","name":"ParIAI","subcategory":"Language","website":"https://parl.ai/","description":"A framework for training and evaluating AI models on a variety of openly available dialogue datasets.","repositories":[{"url":"https://github.com/facebookresearch/ParlAI","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorchnlp.readthedocs.io/en/latest/","id":"modeling--language--pytorch-nlp","logo":"logos/49a408722c78586e14156d60f6d32160a69da86afea96b933f3084dc4157c133.svg","name":"PyTorch-NLP","subcategory":"Language","website":"https://pytorchnlp.readthedocs.io/en/latest/","description":"Basic Utilities for PyTorch Natural Language Processing (NLP)","repositories":[{"url":"https://github.com/PetrochukM/PyTorch-NLP","primary":true}]},{"category":"Modeling","homepage_url":"http://textbrewer.hfl-rc.com/","id":"modeling--language--textbrewer","logo":"logos/118f11cf04792d06063ccac1204986dcba4db290f95137e3dca685a27b15bb3d.svg","name":"TextBrewer","subcategory":"Language","website":"http://textbrewer.hfl-rc.com/","description":"A PyTorch-based knowledge distillation toolkit for natural language processing","repositories":[{"url":"https://github.com/airaria/TextBrewer","primary":true}]},{"category":"Modeling","homepage_url":"https://www.dgl.ai/","id":"modeling--specialized--dgl","logo":"logos/8bc26a2c13a583b1695caeee24b08ead02adb0d16645e0d2763ea37305fae388.svg","name":"DGL","subcategory":"Specialized","website":"https://www.dgl.ai/","description":"Python package built to ease deep learning on graph, on top of existing DL frameworks.  Fast and memory-efficient message passing primitives for training Graph Neural Networks.","repositories":[{"url":"https://github.com/dmlc/dgl/","primary":true}]},{"category":"Modeling","homepage_url":"https://huggingface.co/docs/diffusers/index","id":"modeling--specialized--diffusers","logo":"logos/ffc8bf3d4d9c6e89044e907ea8b49195426ef764da054041f80845be8605c48e.svg","name":"Diffusers","subcategory":"Specialized","website":"https://huggingface.co/docs/diffusers/index","description":"Pretrained diffusion models for generating images, audio, and even 3D structures of molecules. Whether you are looking for a simple inference solution or want to train your own diffusion model, Diffusers is a modular toolbox that supports both","repositories":[{"url":"https://github.com/huggingface/diffusers","primary":true}]},{"category":"Modeling","homepage_url":"https://woven-planet.github.io/l5kit/","id":"modeling--specialized--l5kit","logo":"logos/7dabfc94ffc28d1fd628346c3d70bb5a0fa4ae514b5323cad25267cd71aa3fab.svg","name":"L5Kit","subcategory":"Specialized","website":"https://woven-planet.github.io/l5kit/","description":"A python library with functionality for the development and training of learned prediction, planning and simulation models for autonomous driving applications.","repositories":[{"url":"https://github.com/woven-planet/l5kit","primary":true}]},{"category":"Modeling","homepage_url":"https://pypose.org/","id":"modeling--specialized--pypose","logo":"logos/8513a8257efd437369eb631ace0e7514cfdce3e6297154043bc263c67f49d128.svg","name":"PyPose","subcategory":"Specialized","website":"https://pypose.org/","description":"PyPose is a library for Robot Learning with Physics-based Optimization","repositories":[{"url":"https://github.com/pypose/pypose","primary":true}]},{"category":"Modeling","homepage_url":"https://pypots.com/","id":"modeling--specialized--pypots","logo":"logos/9b443ae59bd33bdee86bbe1d3190c727ce938845d8696ac8e76bd7c662c822a2.svg","name":"PyPOTS","subcategory":"Specialized","website":"https://pypots.com/","description":"a Python toolbox for machine learning on Partially-Observed Time Series","repositories":[{"url":"https://github.com/WenjieDu/PyPOTS","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorchvideo.org/","id":"modeling--specialized--pytorchvideo","logo":"logos/ad52117a8e14a31993e1549cd32f76e6d4ddb403826679eee528774a7404729a.svg","name":"PyTorchVideo","subcategory":"Specialized","website":"https://pytorchvideo.org/","description":"A deep learning library for video understanding research.","repositories":[{"url":"https://github.com/facebookresearch/pytorchvideo","primary":true}]},{"category":"Modeling","homepage_url":"https://ibm.github.io/simulai/","id":"modeling--specialized--simulai","logo":"logos/52d2378814907baeac4813eba9000d2ac5fb8a804f9c7a621b96003bdc3738e2.svg","name":"SimulAI","subcategory":"Specialized","website":"https://ibm.github.io/simulai/","description":"A toolkit with data-driven pipelines for physics-informed machine learning.","repositories":[{"url":"https://github.com/IBM/simulai","primary":true}]},{"category":"Modeling","homepage_url":"https://www.osgeo.org/projects/torchgeo/","id":"modeling--specialized--torchgeo","logo":"logos/0f021d5c7b0d805439d23e941b0a743d16b7cf89fa11b5cc9c19a53d44549420.svg","name":"torchgeo","subcategory":"Specialized","website":"https://www.osgeo.org/projects/torchgeo/","description":"TorchGeo is a toolkit containing datasets, samplers, transforms, and pre-trained models for geospatial data.","repositories":[{"url":"https://github.com/microsoft/torchgeo","primary":true}]},{"category":"Modeling","homepage_url":"https://clinicadl.readthedocs.io/en/latest/","id":"modeling--medical-biology--clinica-dl","logo":"logos/0e35348df86096d30232c0f852e0821acb387f280097ad52f6b298ee03147ee8.svg","name":"Clinica DL","subcategory":"Medical & Biology","website":"https://clinicadl.readthedocs.io/en/latest/","description":"open-source deep learning software for reproducible neuroimaging processing. It can be seen as the deep learning extension of Clinica, an open-source Python library for neuroimaging preprocessing and analysis.","repositories":[{"url":"https://github.com/aramis-lab/clinicadl","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorch.org/ecosystem/","id":"modeling--medical-biology--fusemedml","logo":"logos/bed2d7b1ea133092432cc28a1d20d3314098a2c30624894f1bad0ed7162fa03d.svg","name":"FuseMedML","subcategory":"Medical & Biology","website":"https://pytorch.org/ecosystem/","description":"A python framework accelerating ML based discovery in the medical field by encouraging code reuse","repositories":[{"url":"https://github.com/BiomedSciAI/fuse-med-ml","primary":true}]},{"category":"Modeling","homepage_url":"https://www.nature.com/articles/s44172-023-00066-3","id":"modeling--medical-biology--gandlf","logo":"logos/2c684fbc52871399018ed1bbd4eb4558cf380b37f789128ab453063f072a1377.svg","name":"GaNDLF","subcategory":"Medical & Biology","website":"https://www.nature.com/articles/s44172-023-00066-3","description":"The Generally Nuanced Deep Learning Framework (GaNDLF) for image segmentation and classification, especially in the biomedical field.","repositories":[{"url":"https://github.com/mlcommons/gandlf","primary":true}]},{"category":"Modeling","homepage_url":"https://monai.io/","id":"modeling--medical-biology--monai","logo":"logos/05c4cdff595fa70e0ca8175384c2fbe4efc7c321437d8fd14bd6f13a9671fb74.svg","name":"MONAI","subcategory":"Medical & Biology","website":"https://monai.io/","description":"AI Toolkit for Healthcare Imaging","repositories":[{"url":"https://github.com/Project-MONAI","primary":true}]},{"category":"Modeling","homepage_url":"https://warwick.ac.uk/fac/cross_fac/tia/","id":"modeling--medical-biology--tiatoolbox","logo":"logos/ba4859ff6d65b65bc3b5e1a48fdffcb34c3d0ff8435c11eb1f1aac0120c1224d.svg","name":"TIAToolbox","subcategory":"Medical & Biology","website":"https://warwick.ac.uk/fac/cross_fac/tia/","description":"TIAToolbox is a computational pathology toolbox for pathology image analysis.","repositories":[{"url":"https://github.com/TissueImageAnalytics/tiatoolbox","primary":true}]},{"category":"Modeling","homepage_url":"https://torchdrug.ai/","id":"modeling--medical-biology--torchdrug","logo":"logos/3bfe1124b8618af6e41b5f3da074e88c2bd2ed7a6e1e70cf35dad2f2ecd2ed51.svg","name":"torchdrug","subcategory":"Medical & Biology","website":"https://torchdrug.ai/","description":"A powerful and flexible machine learning platform for drug discovery","repositories":[{"url":"https://github.com/DeepGraphLearning/torchdrug","primary":true}]},{"category":"Modeling","homepage_url":"http://www.torchio.org/","id":"modeling--medical-biology--torchio","logo":"logos/3f53485d82e837e49ad8c2f5b2ca860ac321809c9d7a50f6f4029c49911a158f.svg","name":"TorchIO","subcategory":"Medical & Biology","website":"http://www.torchio.org/","description":"Medical imaging toolkit for deep learning","repositories":[{"url":"https://github.com/fepegar/torchio","primary":true}]},{"category":"Modeling","homepage_url":"https://mmf.sh/","id":"modeling--multimodal--mmf","logo":"logos/0c6791d31524bbcc5d00788ef39db3ff6576fdd3d3b1f8cea530d5c551e9098f.svg","name":"MMF","subcategory":"Multimodal","website":"https://mmf.sh/","description":"A modular framework for vision & language multimodal research.","repositories":[{"url":"https://github.com/facebookresearch/mmf","primary":true}]},{"category":"Modeling","homepage_url":"https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html","id":"modeling--multimodal--nemo","logo":"logos/28338dbf8ea96d2f14e1e737ecab8f55ada4616e445a10a89f0cb2c019ee8f14.svg","name":"NeMo","subcategory":"Multimodal","website":"https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html","description":"A scalable generative AI framework built for researchers and developers working on Large Language Models, Multimodal, and Speech AI (Automatic Speech Recognition and Text-to-Speech)","repositories":[{"url":"https://github.com/NVIDIA/NeMo","primary":true}]},{"category":"Modeling","homepage_url":"https://usb.readthedocs.io/en/main/","id":"modeling--multimodal--usb","logo":"logos/ba2f979d55cfe3b448250c198b2c08437accb672f3f21600f0b3c979a399c9e7.svg","name":"USB","subcategory":"Multimodal","website":"https://usb.readthedocs.io/en/main/","description":"Benchmark tool for developing and evaluating Semi-suprevised learning algorithms.  Includes an implementation of 14 SSL algorithms and 15 tasks for evaluation for CV, NLP, and Audio","repositories":[{"url":"https://github.com/microsoft/Semi-supervised-learning","primary":true}]},{"category":"Modeling","homepage_url":"https://torch-points3d.readthedocs.io/en/latest/","id":"modeling--3d--pytorch-points3d","logo":"logos/7c3c77c9fbd88d4dae1e9d32ef70b0b115ad578cacb4f90dda36f4aaefc4cc0d.svg","name":"PyTorch-Points3d","subcategory":"3D","website":"https://torch-points3d.readthedocs.io/en/latest/","description":"A framework for developing and testing common deep learning models to solve tasks related to unstructured 3D spatial data","repositories":[{"url":"https://github.com/torch-points3d/torch-points3d","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorch3d.org/","id":"modeling--3d--pytorch3d","logo":"logos/88318438fc9c2bbc4989daf11182ed9ec9e685c4f9f97317d978d87f732f9e96.svg","name":"PyTorch3D","subcategory":"3D","website":"https://pytorch3d.org/","description":"PyTorch3D is a library of reusable components for deep learning with 3D data","repositories":[{"url":"https://github.com/facebookresearch/pytorch3d","primary":true}]},{"category":"Modeling","homepage_url":"https://naver.github.io/roma/","id":"modeling--3d--roma","logo":"logos/854eb858a0e2e8dc7b30e28631988dfc00c97e1775f3e74f3f1b37e2010c5954.svg","name":"RoMa","subcategory":"3D","website":"https://naver.github.io/roma/","description":"RoMa (which stands for Rotation Manipulation) provides differentiable mappings between 3D rotation representations, mappings from Euclidean to rotation space, and various utilities related to rotations.","repositories":[{"url":"https://github.com/naver/roma","primary":true}]},{"category":"Modeling","homepage_url":"https://advertorch.readthedocs.io/en/latest/","id":"modeling--adversarial-robustness--advertorch","logo":"logos/eec3e6838be8fa53a5d16513a8d774a10163c261bbef2fbb1172f7f33954dfd9.svg","name":"AdverTorch","subcategory":"Adversarial & Robustness","website":"https://advertorch.readthedocs.io/en/latest/","description":"A Toolbox for Adversarial Robustness Research","repositories":[{"url":"https://github.com/BorealisAI/advertorch","primary":true}]},{"category":"Modeling","homepage_url":"https://ensemble-pytorch.readthedocs.io/","id":"modeling--adversarial-robustness--ensemble-pytorch","logo":"logos/1a5daa080e0d4c6242967eeac5734b744501e8d1bfe8a1f86e4305047a928ef0.svg","name":"Ensemble-Pytorch","subcategory":"Adversarial & Robustness","website":"https://ensemble-pytorch.readthedocs.io/","description":"unified ensemble framework for PyTorch to improve the performance and robustness of your ensemble based deep learning model","repositories":[{"url":"https://github.com/TorchEnsemble-Community/Ensemble-Pytorch","primary":true}]},{"category":"Modeling","homepage_url":"https://captum.ai/docs/introduction.html","id":"modeling--general--captum","logo":"logos/2abc1fc7558376c329b2798f7bcde761b3644e8805d84dc631370e0e76d75b8d.svg","name":"Captum","subcategory":"General","website":"https://captum.ai/docs/introduction.html","description":"An open source, extensible library for model interpretability built on PyTorch.","repositories":[{"url":"https://github.com/pytorch/captum","primary":true}]},{"category":"Modeling","homepage_url":"https://huggingface.co/transformers","id":"modeling--general--transformers","logo":"logos/22ee2a64b64ec10d3f8665a2c99fe71389da44d177ce9688632c462e8627224b.svg","name":"Transformers","subcategory":"General","website":"https://huggingface.co/transformers","description":"Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.","repositories":[{"url":"https://github.com/huggingface/transformers","primary":true}]},{"category":"Modeling","homepage_url":"https://pennylane.ai/","id":"modeling--quantum--pennylane","logo":"logos/2d8e7a169283e296f1d72aad881717481147608ecb440ecb9b92b3c078ce197f.svg","name":"PennyLane","subcategory":"Quantum","website":"https://pennylane.ai/","description":"PennyLane is a cross-platform Python library for quantum computing, quantum machine learning, and quantum chemistry. Train a quantum computer the same way as a neural network.","repositories":[{"url":"https://github.com/PennyLaneAI/pennylane","primary":true}]},{"category":"Training","homepage_url":"https://adaptdl.readthedocs.io/en/latest/","id":"training--general--adaptdl","logo":"logos/532512bdae901d661538ee38bb165d61918199ab2ba8f4d4cf0fddb2ed742647.svg","name":"AdaptDL","subcategory":"General","website":"https://adaptdl.readthedocs.io/en/latest/","description":"AdaptDL is a resource-adaptive deep learning (DL) training and scheduling framework, and is part of the CASL open source project.","repositories":[{"url":"https://github.com/petuum/adaptdl","primary":true}]},{"category":"Training","homepage_url":"https://catalyst-team.com/","id":"training--general--catalyst","logo":"logos/b8f9b0d3ee7df42d688ddfaf95b3177f256d68521167ac27b601778e339fbedc.svg","name":"Catalyst","subcategory":"General","website":"https://catalyst-team.com/","description":"Catalyst is a PyTorch framework for Deep Learning Research and Development. It focuses on reproducibility, rapid experimentation, and codebase reuse so you can create something new rather than write yet another train loop.","repositories":[{"url":"https://github.com/catalyst-team/catalyst","primary":true}]},{"category":"Training","homepage_url":"https://www.colossalai.org/","id":"training--general--colossalai","logo":"logos/2125379104f8c98deea6e3dd3e0b2af88238792c2f41420624c1a142642c69ca.svg","name":"ColossalAI","subcategory":"General","website":"https://www.colossalai.org/","description":"Tools to kickstart distributed training and inference","repositories":[{"url":"https://github.com/hpcaitech/ColossalAI","primary":true}]},{"category":"Training","homepage_url":"http://docs.mosaicml.com/","id":"training--general--composer","logo":"logos/23206110f1d95753c27e1ebe4c63c6bc2c3b86060c4b332516cd9a3931f1900f.svg","name":"composer","subcategory":"General","website":"http://docs.mosaicml.com/","description":"A open-source deep learning training library optimized for scalability and usability, integrating best practices for efficient, multi-node training","repositories":[{"url":"https://github.com/mosaicml/composer","primary":true}]},{"category":"Training","homepage_url":"https://docs.fast.ai/","id":"training--general--fastai","logo":"logos/9b1d9cefe662d9c4a595cbe44fddc8c2d31a2390f6ac3ac0ae025a8c878a53ce.svg","name":"fastai","subcategory":"General","website":"https://docs.fast.ai/","description":"fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches","repositories":[{"url":"https://github.com/fastai/fastai","primary":true}]},{"category":"Training","homepage_url":"https://github.com/microsoft/hummingbird","id":"training--general--hummingbird","logo":"logos/c0d704d4e08b297aadf925661feaf0dece433d3da38e551a9b0b0d326880447f.svg","name":"Hummingbird","subcategory":"General","website":"https://github.com/microsoft/hummingbird","description":"Hummingbird is a library for compiling trained traditional ML models into tensor computations. Hummingbird allows users to seamlessly leverage neural network frameworks (such as PyTorch) to accelerate traditional ML models.","repositories":[{"url":"https://github.com/microsoft/hummingbird","primary":true}]},{"category":"Training","homepage_url":"https://pytorch-ignite.ai/","id":"training--general--ignite","logo":"logos/35bb1388cfcd432baba2f56afef9724cf9bbeca68724e9adcb4232272ad8309f.svg","name":"Ignite","subcategory":"General","website":"https://pytorch-ignite.ai/","description":"High-level library to help with training and evaluating neural networks in PyTorch","repositories":[{"url":"https://github.com/pytorch/ignite","primary":true}]},{"category":"Training","homepage_url":"https://ludwig.ai/latest/","id":"training--general--ludwig","logo":"logos/6e299a3f1f6df294a97064d136dd13a8078ec5ccc3d9cfdf4f3f57faf17e4b3b.svg","name":"ludwig","subcategory":"General","website":"https://ludwig.ai/latest/","description":"Ludwig is a low-code framework for building custom AI models like LLMs and other deep neural networks.","repositories":[{"url":"https://github.com/ludwig-ai/ludwig","primary":true}]},{"category":"Training","homepage_url":"https://poutyne.org/","id":"training--general--poutyne","logo":"logos/a291fe1f4346bc027619c3baebe8eccb7043cece79f64e2582a80056699faa44.svg","name":"Poutyne","subcategory":"General","website":"https://poutyne.org/","description":"Poutyne is a simplified framework for PyTorch and handles much of the boilerplating code needed to train neural networks.","repositories":[{"url":"https://github.com/GRAAL-Research/poutyne","primary":true}]},{"category":"Training","homepage_url":"https://lightning.ai/","id":"training--general--pytorch-lightning","logo":"logos/9ea7a73b721cef9519fd2ac3cc48b9dd167e210bda4ce34ae8c8984d9ad28ebd.svg","name":"PyTorch Lightning","subcategory":"General","website":"https://lightning.ai/","description":"Pretrain, finetune and deploy AI models on multiple GPUs, TPUs with zero code changes.","repositories":[{"url":"https://github.com/Lightning-AI/pytorch-lightning","primary":true}]},{"category":"Training","homepage_url":"https://github.com/skorch-dev/skorch","id":"training--general--skorch","logo":"logos/5fd4c8f1c65f2f5281e64ebe6b8e82bca7b16608042672804f452b8d8f2b1d98.svg","name":"skorch","subcategory":"General","website":"https://github.com/skorch-dev/skorch","description":"A scikit-learn compatible neural network library that wraps PyTorch.","repositories":[{"url":"https://github.com/skorch-dev/skorch","primary":true}]},{"category":"Training","homepage_url":"https://fidelity.github.io/stoke/","id":"training--general--stoke","logo":"logos/00076432de043a325ce5d921de4d7474db9c0f85e50fdc5f48ef3bc425417831.svg","name":"stoke","subcategory":"General","website":"https://fidelity.github.io/stoke/","description":"A lightweight wrapper for PyTorch that provides a simple declarative API for context switching between devices (e.g. CPU, GPU), distributed modes, mixed-precision, and PyTorch extensions. This allows you to switch from local full-precision CPU to mixed-precision distributed multi-GPU with extensions (like optimizer state sharding) by simply changing a few declarative flags.","repositories":[{"url":"https://github.com/StanfordPL/stoke","primary":true}]},{"category":"Training","homepage_url":"https://yoshitomo-matsubara.net/torchdistill/","id":"training--general--torchdistill","logo":"logos/00e6cd8399a844be633526e835a2bff2a35c27c464134204177f96b484d0b393.svg","name":"torchdistill","subcategory":"General","website":"https://yoshitomo-matsubara.net/torchdistill/","description":"Offers various state-of-the-art knowledge distillation methods and enables you to design (new) experiments simply by editing a declarative yaml config file.","repositories":[{"url":"https://github.com/yoshitomo-matsubara/torchdistill","primary":true}]},{"category":"Training","homepage_url":"https://lightning.ai/docs/torchmetrics/","id":"training--general--torchmetrics","logo":"logos/fe7ab2ceb03b0c3b20725bb4810500052a76b2285265de910812dfa0abbbdf6c.svg","name":"TorchMetrics","subcategory":"General","website":"https://lightning.ai/docs/torchmetrics/","description":"Machine learning metrics for distributed, scalable PyTorch applications.","repositories":[{"url":"https://github.com/Lightning-AI/torchmetrics","primary":true}]},{"category":"Training","homepage_url":"https://baal.readthedocs.io/","id":"training--probabilistic-optimization--baal","logo":"logos/e52fe477062933115c9eee93722f40f2dba311e6935fb12b5bf490fc94c26eb5.svg","name":"baal","subcategory":"Probabilistic & Optimization","website":"https://baal.readthedocs.io/","description":"Baal is a Bayesian active learning library. Provides methods to do posterior distribution sampling in order to maximize the efficiency of labelling during active learning. Our library is suitable for research and industrial applications.","repositories":[{"url":"https://github.com/baal-org/baal","primary":true}]},{"category":"Training","homepage_url":"https://botorch.org/","id":"training--probabilistic-optimization--botorch","logo":"logos/bf6001cce117af4ae13495875da21ba11ba34f5d42b525ce555f61452ad9fc6d.svg","name":"BoTorch","subcategory":"Probabilistic & Optimization","website":"https://botorch.org/","description":"A Framework for Efficient Monte-Carlo Bayesian Optimization","repositories":[{"url":"https://github.com/pytorch/botorch","primary":true}]},{"category":"Training","homepage_url":"https://arxiv.org/abs/1809.11165","id":"training--probabilistic-optimization--gpytorch","logo":"logos/edd7c89043cddc740dd6ccd3746aee9f57a590b76e93440eff93fb7272c3f4ce.svg","name":"GPyTorch","subcategory":"Probabilistic & Optimization","website":"https://arxiv.org/abs/1809.11165","description":"GPyTorch is a Gaussian process library implemented using PyTorch. GPyTorch is designed for creating scalable, flexible, and modular Gaussian process models with ease","repositories":[{"url":"https://github.com/cornellius-gp/gpytorch","primary":true}]},{"category":"Training","homepage_url":"https://optuna.org/","id":"training--probabilistic-optimization--optuna","logo":"logos/221ccf5311fc9739ea42133e7727c4e1e3bbdb761fee27e5f71434e93ea35740.svg","name":"Optuna","subcategory":"Probabilistic & Optimization","website":"https://optuna.org/","description":"Optuna is an automatic hyperparameter optimization software framework, particularly designed for machine learning.","repositories":[{"url":"https://github.com/optuna/optuna","primary":true}]},{"category":"Training","homepage_url":"https://pomegranate.readthedocs.io/en/latest/","id":"training--probabilistic-optimization--pomegranate","logo":"logos/ebf8effc430934c78a17464087fe36856c0dfe2c390f3e278beac637efb264e0.svg","name":"Pomegranate","subcategory":"Probabilistic & Optimization","website":"https://pomegranate.readthedocs.io/en/latest/","description":"pomegranate is a Python package that implements fast and flexible probabilistic models ranging from individual probability distributions to compositional models such as Bayesian networks and hidden Markov models","repositories":[{"url":"https://github.com/jmschrei/pomegranate","primary":true}]},{"category":"Training","homepage_url":"https://pyro.ai/","id":"training--probabilistic-optimization--pyro","logo":"logos/ed7e2a4d5d7f216c73dc8d10febb6720c12b706bd262296605f82b5f01801d60.svg","name":"Pyro","subcategory":"Probabilistic & Optimization","website":"https://pyro.ai/","description":"Deep universal probabilistic programming with Python and PyTorch","repositories":[{"url":"https://github.com/pyro-ppl/pyro","primary":true}]},{"category":"Training","homepage_url":"https://crypten.readthedocs.io/en/latest/","id":"training--privacy--crypten","logo":"logos/a84661f05548b18ae3aa8e49e95af0fbcc12300d9482db746e87a8ab2f596531.svg","name":"CrypTen","subcategory":"Privacy","website":"https://crypten.readthedocs.io/en/latest/","description":"CrypTen is a Privacy Preserving Machine Learning framework written using PyTorch to train models using encrypted data. It is currently not production ready and its main use is as a research framework","repositories":[{"url":"https://github.com/facebookresearch/CrypTen","primary":true}]},{"category":"Training","homepage_url":"https://opacus.ai/","id":"training--privacy--opacus","logo":"logos/93e7f58529785d31148daadf57a83ea2c2f8a5881b6825df426596b79b6954ad.svg","name":"Opacus","subcategory":"Privacy","website":"https://opacus.ai/","description":"Train PyTorch models with Differential Privacy","repositories":[{"url":"https://github.com/pytorch/opacus","primary":true}]},{"category":"Training","homepage_url":"https://www.openmined.org/","id":"training--privacy--pysyft","logo":"logos/ddcdd70695dcc0780072851c60375522b8a616c35ffdec80717cf32b87d21310.svg","name":"PySyft","subcategory":"Privacy","website":"https://www.openmined.org/","description":"Perform data science on data that remains in someone else's server","repositories":[{"url":"https://github.com/OpenMined/PySyft","primary":true}]},{"category":"Training","homepage_url":"http://avalanche.continualai.org/","id":"training--continuous-learning--avalanche","logo":"logos/6db724b646af4bb6a96bf1e939a4018ee5f01db33e92af69a611275266ba90f5.svg","name":"avalanche","subcategory":"Continuous Learning","website":"http://avalanche.continualai.org/","description":"Avalanche is an End-to-End Continual Learning Library based on PyTorch, for fast prototyping, training, and reproducible evaluation of continual learning algorithms.","repositories":[{"url":"https://github.com/ContinualAI/avalanche","primary":true}]},{"category":"Training","homepage_url":"https://renate.readthedocs.io/en/latest/","id":"training--continuous-learning--renate","logo":"logos/e9fb21ed75b6d1f586d07a501eb6f349489335f0bbc79c436f625b5f0e753577.svg","name":"Renate","subcategory":"Continuous Learning","website":"https://renate.readthedocs.io/en/latest/","description":"Renate is a Python package for automatic retraining of neural networks models. It uses advanced Continual Learning and Lifelong Learning algorithms to achieve this purpose.","repositories":[{"url":"https://github.com/awslabs/renate","primary":true}]},{"category":"Training","homepage_url":"https://flower.ai/","id":"training--federated-learning--flower","logo":"logos/af4acf3f0922e8bb18cd7439136d299b7c8ddd7c5b8e7574bb31c17c6b4450b1.svg","name":"Flower","subcategory":"Federated Learning","website":"https://flower.ai/","description":"A unified approach to federated learning, analytics, and evaluation. Federate any workload, any ML framework, and any programming language","repositories":[{"url":"https://github.com/adap/flower","primary":true}]},{"category":"Training","homepage_url":"https://docs.substra.org/","id":"training--federated-learning--substra","logo":"logos/57e63c3a4288f965a164da315553b98b67b369bbee4e6d9a24cdfd6cb43bc380.svg","name":"Substra","subcategory":"Federated Learning","website":"https://docs.substra.org/","description":"Substra is used to run complex federated learning experiments at scale.","repositories":[{"url":"https://github.com/Substra","primary":true}]},{"category":"Training","homepage_url":"https://github.com/pfnet/pfrl","id":"training--reinforcement-learning--pfrl","logo":"logos/e207d794eaca709d5667f9e92cefba0497d2124c413b11e863c1246dc2307b89.svg","name":"PFRL","subcategory":"Reinforcement Learning","website":"https://github.com/pfnet/pfrl","description":"PFRL is a PyTorch-based deep reinforcement learning library","repositories":[{"url":"https://github.com/pfnet/pfrl","primary":true}]},{"category":"Training","homepage_url":"https://stable-baselines3.readthedocs.io/","id":"training--reinforcement-learning--stable-baselines3","logo":"logos/a0f8f03828e020f203be7c6c0e19ccab88e2fe89feeaad3d517c79033bae9edf.svg","name":"Stable Baselines3","subcategory":"Reinforcement Learning","website":"https://stable-baselines3.readthedocs.io/","description":"Stable Baselines3 (SB3) is a set of implementations of reinforcement learning algorithms","repositories":[{"url":"https://github.com/DLR-RM/stable-baselines3","primary":true}]},{"category":"Training","homepage_url":"https://pyg.org/","id":"training--graph--pytorch-geometric","logo":"logos/5bf81a10e91e5b5336f31c52500e47e02dc3c860f3d66c7b4936161107dc12c9.svg","name":"PyTorch Geometric","subcategory":"Graph","website":"https://pyg.org/","description":"Graph Neural Network Library for PyTorch","repositories":[{"url":"https://github.com/pyg-team/pytorch_geometric","primary":true}]},{"category":"Training","homepage_url":"https://github.com/benedekrozemberczki/pytorch_geometric_temporal","id":"training--graph--pytorch-geometric-temporal","logo":"logos/e178f77ad4a1b8ba7fa3e617cc445a8b47c1dd88a61972330752cc7ee6dbdd21.svg","name":"PyTorch Geometric Temporal","subcategory":"Graph","website":"https://github.com/benedekrozemberczki/pytorch_geometric_temporal","description":"PyTorch Geometric Temporal is a Spatiotemporal Signal Processing with Neural Machine Learning Models","repositories":[{"url":"https://github.com/benedekrozemberczki/pytorch_geometric_temporal","primary":true}]},{"category":"Training","homepage_url":"https://pykale.github.io/","id":"training--multimodal--pykale","logo":"logos/1514ccbb316a3ae5a772df0cb382bd6917c12793cc8174f0699d4fb19d1acec0.svg","name":"PyKale","subcategory":"Multimodal","website":"https://pykale.github.io/","description":"PyKale has a unified pipeline-based API and focuses on multimodal learning and transfer learning for graphs, images, and videos at the moment, with supporting models on deep learning and dimensionality reduction.","repositories":[{"url":"https://github.com/pykale/pykale","primary":true}]},{"category":"Training","homepage_url":"https://kevinmusgrave.github.io/pytorch-metric-learning/","id":"training--self-supervised--pytorch-metric-learning","logo":"logos/64fe0aa1a6facd5730cee30d3904885e90f56c6cc79d9f9edda241ecf4585ff7.svg","name":"PyTorch Metric Learning","subcategory":"Self supervised","website":"https://kevinmusgrave.github.io/pytorch-metric-learning/","description":"Modular, flexible, and extensible library for deep metric learning.","repositories":[{"url":"https://github.com/KevinMusgrave/pytorch-metric-learning","primary":true}]},{"category":"Training","homepage_url":"https://github.com/ray-project/ray","id":"training--distributed--ray","logo":"logos/3975c0f455d00dfab6b5c78281eb7c5dd6ffcf105bcc8c78764eb09a5ed534a6.svg","name":"Ray","subcategory":"Distributed","website":"https://github.com/ray-project/ray","description":"Ray is a unified framework for scaling AI and Python applications. Ray consists of a core distributed runtime and a set of AI Libraries for accelerating ML workloads.","repositories":[{"url":"https://github.com/ray-project/ray","primary":true}]},{"category":"Training","homepage_url":"https://hanruiwanghw.wixsite.com/torchquantum","id":"training--quantum--torchquantum","logo":"logos/eba8a1f3cf2a73d23a295af0b6e67dcb61560ca1630acae2f929fea8cd863b90.svg","name":"TorchQuantum","subcategory":"Quantum","website":"https://hanruiwanghw.wixsite.com/torchquantum","description":"A framework for Quantum Classical Simulation, Quantum Machine Learning, Quantum Neural Networks, Parameterized Quantum Circuits with support for easy deployments on real quantum computers.","repositories":[{"url":"https://github.com/mit-han-lab/torchquantum","primary":true}]},{"category":"Optimizations","homepage_url":"https://einops.rocks/","id":"optimizations--general--einops","logo":"logos/b5a90edf576208a5d90039a11703e94d01d4d4941c3bb98702a13de77d0cbec3.svg","name":"einops","subcategory":"General","website":"https://einops.rocks/","description":"Flexible and powerful tensor operations for readable and reliable code (for pytorch, jax, TF and others)","repositories":[{"url":"https://github.com/arogozhnikov/einops","primary":true}]},{"category":"Optimizations","homepage_url":"https://higher.readthedocs.io/en/latest/.","id":"optimizations--general--higher","logo":"logos/1b11a1d950e1c79a1d207dbd7cd3233a207fa9056d41dd6d8f6d826f136038ff.svg","name":"higher","subcategory":"General","website":"https://higher.readthedocs.io/en/latest/.","description":"higher is a pytorch library allowing users to obtain higher order gradients over losses spanning training loops rather than individual training steps.","repositories":[{"url":"https://github.com/facebookresearch/higher","primary":true}]},{"category":"Optimizations","homepage_url":"https://ivy.dev/","id":"optimizations--general--ivy","logo":"logos/4ac7177a12ab6aa7b56c2420367cbe3b6e1be0de2f9753d69198f5ca9a7731bb.svg","name":"ivy","subcategory":"General","website":"https://ivy.dev/","description":"Convert Machine Learning Code Between Frameworks","repositories":[{"url":"https://github.com/ivy-llc/ivy","primary":true}]},{"category":"Optimizations","homepage_url":"https://intel.github.io/neural-compressor/latest/docs/source/Welcome.html","id":"optimizations--general--neural-compressor","logo":"logos/ba40986b1563b5634522df1bb286e54e543fea3a4ce7e5d0f72c2de633c074f5.svg","name":"neural-compressor","subcategory":"General","website":"https://intel.github.io/neural-compressor/latest/docs/source/Welcome.html","description":"An open-source Python library supporting popular model compression techniques on all deep learning frameworks.","repositories":[{"url":"https://github.com/intel/neural-compressor","primary":true}]},{"category":"Optimizations","homepage_url":"http://tensorly.org/","id":"optimizations--general--tensorly","logo":"logos/d4d2be7563e5a626bf144163697a53e71a99556dc4fdeb8b614bdc7a24793a6e.svg","name":"TensorLy","subcategory":"General","website":"http://tensorly.org/","description":"TensorLy is a Python library that aims at making tensor learning simple and accessible. It allows to easily perform tensor decomposition, tensor learning and tensor algebra. Its backend system allows to seamlessly perform computation with NumPy, PyTorch, JAX, TensorFlow, CuPy or Paddle, and run methods at scale on CPU or GPU.","repositories":[{"url":"https://github.com/tensorly/tensorly","primary":true}]},{"category":"Optimizations","homepage_url":"https://torchopt.readthedocs.io/en/latest/","id":"optimizations--general--torchopt","logo":"logos/fa7428c96683f978432a500f84b389bd2f5a07cb9738885282a728a9015c5cfd.svg","name":"Torchopt","subcategory":"General","website":"https://torchopt.readthedocs.io/en/latest/","description":"An efficient library for differentiable optimization built upon PyTorch","repositories":[{"url":"https://github.com/metaopt/TorchOpt","primary":true}]},{"category":"Optimizations","homepage_url":"https://ml.energy/zeus/","id":"optimizations--general--zeus","logo":"logos/88fe3408a97b0da3dfbd5328126047c69b1627ea7655a2379de2169c0dc701c2.svg","name":"Zeus","subcategory":"General","website":"https://ml.energy/zeus/","description":"Zeus is a library for measuring the energy consumption of Deep Learning workloads and optimizing their energy consumption.","repositories":[{"url":"https://github.com/ml-energy/zeus","primary":true}]},{"category":"Optimizations","homepage_url":"https://depyf.readthedocs.io/en/latest/","id":"optimizations--compilers-runtimes--depyf","logo":"logos/e4a063d36b8096ad076ac1c71881f1be4ccc0a18433cd7541d08de40f2c3370f.svg","name":"Depyf","subcategory":"Compilers & Runtimes","website":"https://depyf.readthedocs.io/en/latest/","description":"depyf is a tool to help you understand debug and get insights into pytorch.compile","repositories":[{"url":"https://github.com/thuml/depyf","primary":true}]},{"category":"Optimizations","homepage_url":"https://github.com/pytorch/glow","id":"optimizations--compilers-runtimes--glow","logo":"logos/b3b7299a3f02acbea42cc57cc86165e6ca112e2729f9f7c3b5284ec36b263bf8.svg","name":"Glow","subcategory":"Compilers & Runtimes","website":"https://github.com/pytorch/glow","description":"Glow is a machine learning compiler and execution engine for hardware accelerators. It is designed to be used as a backend for high-level machine learning frameworks. The compiler is designed to allow state of the art compiler optimizations and code generation of neural network graphs","repositories":[{"url":"https://github.com/pytorch/glow","primary":true}]},{"category":"Optimizations","homepage_url":"https://intel.github.io/intel-extension-for-pytorch/","id":"optimizations--compilers-runtimes--intel-extension-for-pytorch","logo":"logos/149058a8b3c96359ac2f000c8958b4899897602728d52d917f9335d1e0273617.svg","name":"intel-extension-for-pytorch","subcategory":"Compilers & Runtimes","website":"https://intel.github.io/intel-extension-for-pytorch/","description":"A Python extension to optimize performance on an Intel platform.","repositories":[{"url":"https://github.com/intel/intel-extension-for-pytorch","primary":true}]},{"category":"Optimizations","homepage_url":"https://onnxruntime.ai/","id":"optimizations--compilers-runtimes--onnx-runtime","logo":"logos/a2ab7ad7ece050a1a7e0e667813b6992c1abc606d2112dd11c8c84836b5ba522.svg","name":"ONNX runtime","subcategory":"Compilers & Runtimes","website":"https://onnxruntime.ai/","description":"High performance ML inferencing and training accelerator","repositories":[{"url":"https://github.com/microsoft/onnxruntime","primary":true}]},{"category":"Optimizations","homepage_url":"https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/","id":"optimizations--compilers-runtimes--poptorch","logo":"logos/941ac64f6b2ec287a2dfc558c637747c9af0d2acdcf5e6148bdbfc5e2f8a81d5.svg","name":"PopTorch","subcategory":"Compilers & Runtimes","website":"https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/","description":"PopTorch is a set of extensions for PyTorch enabling models to be trained, evaluated and used on the Graphcore IPU.","repositories":[{"url":"https://github.com/graphcore/poptorch","primary":true}]},{"category":"Optimizations","homepage_url":"https://www.nebuly.com/","id":"optimizations--compilers-runtimes--speedster","logo":"logos/ec9ec4b18b7c4f05d7caecffa57b81cf8639ba3442d8cbadba3b2bf53e806961.svg","name":"Speedster","subcategory":"Compilers & Runtimes","website":"https://www.nebuly.com/","description":"Speedster reduces inference costs by leveraging SOTA optimization techniques that best couple your AI models with the underlying hardware (GPUs and CPUs).","repositories":[{"url":"https://github.com/nebuly-ai/optimate/tree/main/optimization/speedster","primary":true}]},{"category":"Optimizations","homepage_url":"https://pytorch.org/TensorRT/","id":"optimizations--compilers-runtimes--torch-tensorrt","logo":"logos/07dbeb39c385db2b246f1fb02d2534f65455facf03f6249afc3eaf34baaddfc1.svg","name":"Torch-TensorRT","subcategory":"Compilers & Runtimes","website":"https://pytorch.org/TensorRT/","description":"Torch-TensorRT is a inference compiler for PyTorch, targeting NVIDIA GPUs via NVIDIA’s TensorRT Deep Learning Optimizer and Runtime.","repositories":[{"url":"https://github.com/RizhaoCai/PyTorch_ONNX_TensorRT","primary":true}]},{"category":"Optimizations","homepage_url":"https://clear.ml/","id":"optimizations--mlops--clear-ml","logo":"logos/b8f9b0d3ee7df42d688ddfaf95b3177f256d68521167ac27b601778e339fbedc.svg","name":"Clear ML","subcategory":"MLOps","website":"https://clear.ml/","description":"Suite of tools to streamline your AI workflow.","repositories":[{"url":"https://github.com/allegroai/clearml","primary":true}]},{"category":"Optimizations","homepage_url":"https://determined.ai/","id":"optimizations--mlops--determined","logo":"logos/6f06ce54ac2345f4d76475807a8d81d20d4f6d8f1f017ac591fb22f312ef329c.svg","name":"Determined","subcategory":"MLOps","website":"https://determined.ai/","description":"Determined is an open-source machine learning platform that simplifies distributed training, hyperparameter tuning, experiment tracking, and resource management. Works with PyTorch and TensorFlow.","repositories":[{"url":"https://github.com/determined-ai/determined","primary":true}]},{"category":"Optimizations","homepage_url":"https://github.com/asyml/forte","id":"optimizations--mlops--forte","logo":"logos/841fb71182aaea1282f014f735fb0f7db557d72aa48bcb0b9807fde0859f958d.svg","name":"forte","subcategory":"MLOps","website":"https://github.com/asyml/forte","description":"Forte is a flexible and powerful ML workflow builder.","repositories":[{"url":"https://github.com/asyml/forte","primary":true}]},{"category":"Optimizations","homepage_url":"https://hydra.cc/","id":"optimizations--mlops--hydra","logo":"logos/cccea004a9de0d9bfd5ab086ec975ab271e67b75172e0526d0294b8e158b6db2.svg","name":"Hydra","subcategory":"MLOps","website":"https://hydra.cc/","description":"simplifies the development of research and other complex applications. The key feature is the ability to dynamically create a hierarchical configuration by composition and override it through config files and the command line. The name Hydra comes from its ability to run multiple similar jobs - much like a Hydra with multiple heads.","repositories":[{"url":"https://github.com/facebookresearch/hydra","primary":true}]},{"category":"Optimizations","homepage_url":"https://lf1-io.github.io/padl/latest/","id":"optimizations--mlops--padl","logo":"logos/c0324d6b677e731d34b894562042072e4a31734082e9134609e1b68c251bc3d9.svg","name":"padl","subcategory":"MLOps","website":"https://lf1-io.github.io/padl/latest/","description":"A pipeline builder for PyTorch.","repositories":[{"url":"https://github.com/lf1-io/padl","primary":true}]},{"category":"Optimizations","homepage_url":"https://polyaxon.com/","id":"optimizations--mlops--polyaxon","logo":"logos/c8eb66406bda3aeb5e725039da192ab06ab57b2fa394f0a8ea06e57997fc48c4.svg","name":"Polyaxon","subcategory":"MLOps","website":"https://polyaxon.com/","description":"MLOps Tools For Managing & Orchestrating The Machine Learning LifeCycle","repositories":[{"url":"https://github.com/polyaxon/polyaxon","primary":true}]},{"category":"Optimizations","homepage_url":"https://www.deepspeed.ai/","id":"optimizations--distributed--deepspeed","logo":"logos/6a721f2f0c7a39901db79faf3d4307b17472c558462574a3ad699666f4d0e3f3.svg","name":"DeepSpeed","subcategory":"Distributed","website":"https://www.deepspeed.ai/","description":"DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.","repositories":[{"url":"https://github.com/microsoft/DeepSpeed","primary":true}]},{"category":"Optimizations","homepage_url":"https://github.com/facebookresearch/fairscale","id":"optimizations--distributed--fairscale","logo":"logos/76b44191e2f21640c78f4d1afc3679f6bdefb6187441da1a84222ee5be3fb5f7.svg","name":"FairScale","subcategory":"Distributed","website":"https://github.com/facebookresearch/fairscale","description":"PyTorch extension library for high performance and large scale training. This library extends basic PyTorch capabilities while adding new SOTA scaling techniques.","repositories":[{"url":"https://github.com/facebookresearch/fairscale","primary":true}]},{"category":"Optimizations","homepage_url":"http://horovod.ai/","id":"optimizations--distributed--horovod","logo":"logos/a6f46dcbeb116393f35638875cc39a90f61ebc28453af34bf89ce3185da131ae.svg","name":"Horovod","subcategory":"Distributed","website":"http://horovod.ai/","description":"Horovod is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet","repositories":[{"url":"https://github.com/horovod/horovod","primary":true}]},{"category":"Optimizations","homepage_url":"https://pytorchfi.dev/","id":"optimizations--adversarial-robustness--pytorchfi","logo":"logos/4940f3cf2023e817b489c95cca20b0effbac6407db28e7f6eabe7cd4177aa5e5.svg","name":"pytorchfi","subcategory":"Adversarial & Robustness","website":"https://pytorchfi.dev/","description":"A runtime fault injection tool for PyTorch","repositories":[{"url":"https://github.com/pytorchfi/pytorchfi","primary":true}]},{"category":"Optimizations","homepage_url":"https://torchdrift.org/","id":"optimizations--adversarial-robustness--torchdrift","logo":"logos/7b94cddf3ba924eb7e58f6fb4fb6dab03b4874f5331cf51e61fe7ea15b413d31.svg","name":"TorchDrift","subcategory":"Adversarial & Robustness","website":"https://torchdrift.org/","description":"TorchDrift is a data and concept drift library for PyTorch. It lets you monitor your PyTorch models to see if they operate within spec.","repositories":[{"url":"https://github.com/TorchDrift/TorchDrift","primary":true}]},{"category":"Optimizations","homepage_url":"https://github.com/octoml/octoml-profile","id":"optimizations--profiling--octoml-profiler","logo":"logos/6a0430bf99ada8d6b9a2f7c296d8719bd6d5081f40036783c1ee51c58ae73217.svg","name":"OctoML Profiler","subcategory":"Profiling","website":"https://github.com/octoml/octoml-profile","description":"octoml-profile is a python library and cloud service that enables ML engineers to easily assess the performance and cost of PyTorch models on cloud hardware with state-of-the-art ML acceleration technology.","repositories":[{"url":"https://github.com/octoml/octoml-profile","primary":true}]}]}