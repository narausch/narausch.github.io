{"category":{"name":"Optimizations","normalized_name":"optimizations","subcategories":[{"name":"General","normalized_name":"general"},{"name":"Compilers & Runtimes","normalized_name":"compilers-runtimes"},{"name":"MLOps","normalized_name":"mlops"},{"name":"Distributed","normalized_name":"distributed"}]},"foundation":"PyTorch","items":[{"category":"Optimizations","id":"optimizations--general--einops","name":"einops","logo":"logos/b5a90edf576208a5d90039a11703e94d01d4d4941c3bb98702a13de77d0cbec3.svg","subcategory":"General","website":"https://einops.rocks/","description":"Flexible and powerful tensor operations for readable and reliable code (for pytorch, jax, TF and others)","primary_repository_url":"https://github.com/arogozhnikov/einops"},{"category":"Optimizations","id":"optimizations--general--higher","name":"higher","logo":"logos/1b11a1d950e1c79a1d207dbd7cd3233a207fa9056d41dd6d8f6d826f136038ff.svg","subcategory":"General","website":"https://higher.readthedocs.io/en/latest/.","description":"higher is a pytorch library allowing users to obtain higher order gradients over losses spanning training loops rather than individual training steps.","primary_repository_url":"https://github.com/facebookresearch/higher"},{"category":"Optimizations","id":"optimizations--general--ivy","name":"ivy","logo":"logos/4ac7177a12ab6aa7b56c2420367cbe3b6e1be0de2f9753d69198f5ca9a7731bb.svg","subcategory":"General","website":"https://ivy.dev/","description":"Convert Machine Learning Code Between Frameworks","primary_repository_url":"https://github.com/ivy-llc/ivy"},{"category":"Optimizations","id":"optimizations--general--neural-compressor","name":"neural-compressor","logo":"logos/ba40986b1563b5634522df1bb286e54e543fea3a4ce7e5d0f72c2de633c074f5.svg","subcategory":"General","website":"https://intel.github.io/neural-compressor/latest/docs/source/Welcome.html","description":"An open-source Python library supporting popular model compression techniques on all deep learning frameworks.","primary_repository_url":"https://github.com/intel/neural-compressor"},{"category":"Optimizations","id":"optimizations--general--tensorly","name":"TensorLy","logo":"logos/d4d2be7563e5a626bf144163697a53e71a99556dc4fdeb8b614bdc7a24793a6e.svg","subcategory":"General","website":"http://tensorly.org/","description":"TensorLy is a Python library that aims at making tensor learning simple and accessible. It allows to easily perform tensor decomposition, tensor learning and tensor algebra. Its backend system allows to seamlessly perform computation with NumPy, PyTorch, JAX, TensorFlow, CuPy or Paddle, and run methods at scale on CPU or GPU.","primary_repository_url":"https://github.com/tensorly/tensorly"},{"category":"Optimizations","id":"optimizations--general--torcharrow","name":"torcharrow","logo":"logos/c2dcd89ea2a9e0f9465d2a642e9a85f8811510080684404650682e812dfa7615.svg","subcategory":"General","website":"https://pytorch.org/torcharrow/beta/index.html","description":"TorchArrow is a torch.Tensor-like Python DataFrame library for data preprocessing in deep learning. It supports multiple execution runtimes and Arrow as a common format.","primary_repository_url":"https://github.com/pytorch/torcharrow"},{"category":"Optimizations","id":"optimizations--general--tensordict","name":"tensordict","logo":"logos/786f206855ed9083bcca983901e4c387fcd90182d555b95254efbe6ca0abbd32.svg","subcategory":"General","website":"https://pytorch.org/tensordict/stable/index.html","description":"TensorDict is a dictionary-like class that inherits properties from tensors, such as indexing, shape operations, casting to device etc.","primary_repository_url":"https://github.com/pytorch/tensordict"},{"category":"Optimizations","id":"optimizations--general--torchao","name":"torchao","logo":"logos/638990fe07bc0811e3fe713ae9ed527976ec7a9fb6c85f5c7df7a35dc4067a97.svg","subcategory":"General","website":"https://pytorch.org/blog/pytorch-native-architecture-optimization/","description":"PyTorch library for custom data types & optimizations. Quantize and sparsify weights, gradients, optimizers & activations for inference and training.","primary_repository_url":"https://github.com/pytorch/ao"},{"category":"Optimizations","id":"optimizations--general--torchopt","name":"Torchopt","logo":"logos/fa7428c96683f978432a500f84b389bd2f5a07cb9738885282a728a9015c5cfd.svg","subcategory":"General","website":"https://torchopt.readthedocs.io/en/latest/","description":"An efficient library for differentiable optimization built upon PyTorch","primary_repository_url":"https://github.com/metaopt/TorchOpt"},{"category":"Optimizations","id":"optimizations--general--zeus","name":"Zeus","logo":"logos/88fe3408a97b0da3dfbd5328126047c69b1627ea7655a2379de2169c0dc701c2.svg","subcategory":"General","website":"https://ml.energy/zeus/","description":"Zeus is a library for measuring the energy consumption of Deep Learning workloads and optimizing their energy consumption.","primary_repository_url":"https://github.com/ml-energy/zeus"},{"category":"Optimizations","id":"optimizations--compilers-runtimes--depyf","name":"Depyf","logo":"logos/e4a063d36b8096ad076ac1c71881f1be4ccc0a18433cd7541d08de40f2c3370f.svg","subcategory":"Compilers & Runtimes","website":"https://depyf.readthedocs.io/en/latest/","description":"depyf is a tool to help you understand debug and get insights into pytorch.compile","primary_repository_url":"https://github.com/thuml/depyf"},{"category":"Optimizations","id":"optimizations--compilers-runtimes--glow","name":"Glow","logo":"logos/b3b7299a3f02acbea42cc57cc86165e6ca112e2729f9f7c3b5284ec36b263bf8.svg","subcategory":"Compilers & Runtimes","website":"https://github.com/pytorch/glow","description":"Glow is a machine learning compiler and execution engine for hardware accelerators. It is designed to be used as a backend for high-level machine learning frameworks. The compiler is designed to allow state of the art compiler optimizations and code generation of neural network graphs","primary_repository_url":"https://github.com/pytorch/glow"},{"category":"Optimizations","id":"optimizations--compilers-runtimes--intel-extension-for-pytorch","name":"intel-extension-for-pytorch","logo":"logos/149058a8b3c96359ac2f000c8958b4899897602728d52d917f9335d1e0273617.svg","subcategory":"Compilers & Runtimes","website":"https://intel.github.io/intel-extension-for-pytorch/","description":"A Python extension to optimize performance on an Intel platform.","primary_repository_url":"https://github.com/intel/intel-extension-for-pytorch"},{"category":"Optimizations","id":"optimizations--compilers-runtimes--octoml-profiler","name":"OctoML Profiler","logo":"logos/6a0430bf99ada8d6b9a2f7c296d8719bd6d5081f40036783c1ee51c58ae73217.svg","subcategory":"Compilers & Runtimes","website":"https://github.com/octoml/octoml-profile","description":"octoml-profile is a python library and cloud service that enables ML engineers to easily assess the performance and cost of PyTorch models on cloud hardware with state-of-the-art ML acceleration technology.","primary_repository_url":"https://github.com/octoml/octoml-profile"},{"category":"Optimizations","id":"optimizations--compilers-runtimes--onnx-runtime","name":"ONNX runtime","logo":"logos/a2ab7ad7ece050a1a7e0e667813b6992c1abc606d2112dd11c8c84836b5ba522.svg","subcategory":"Compilers & Runtimes","website":"https://onnxruntime.ai/","description":"High performance ML inferencing and training accelerator","primary_repository_url":"https://github.com/microsoft/onnxruntime"},{"category":"Optimizations","id":"optimizations--compilers-runtimes--poptorch","name":"PopTorch","logo":"logos/941ac64f6b2ec287a2dfc558c637747c9af0d2acdcf5e6148bdbfc5e2f8a81d5.svg","subcategory":"Compilers & Runtimes","website":"https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/","description":"PopTorch is a set of extensions for PyTorch enabling models to be trained, evaluated and used on the Graphcore IPU.","primary_repository_url":"https://github.com/graphcore/poptorch"},{"category":"Optimizations","id":"optimizations--compilers-runtimes--speedster","name":"Speedster","logo":"logos/ec9ec4b18b7c4f05d7caecffa57b81cf8639ba3442d8cbadba3b2bf53e806961.svg","subcategory":"Compilers & Runtimes","website":"https://www.nebuly.com/","description":"Speedster reduces inference costs by leveraging SOTA optimization techniques that best couple your AI models with the underlying hardware (GPUs and CPUs).","primary_repository_url":"https://github.com/nebuly-ai/optimate/tree/main/optimization/speedster"},{"category":"Optimizations","id":"optimizations--compilers-runtimes--torch-tensorrt","name":"Torch-TensorRT","logo":"logos/07dbeb39c385db2b246f1fb02d2534f65455facf03f6249afc3eaf34baaddfc1.svg","subcategory":"Compilers & Runtimes","website":"https://pytorch.org/TensorRT/","description":"Torch-TensorRT is a inference compiler for PyTorch, targeting NVIDIA GPUs via NVIDIAâ€™s TensorRT Deep Learning Optimizer and Runtime.","primary_repository_url":"https://github.com/RizhaoCai/PyTorch_ONNX_TensorRT"},{"category":"Optimizations","id":"optimizations--compilers-runtimes--pytorchxla","name":"PyTorchXLA","logo":"logos/56585018fdef58028329687f94025e78d6de2f303e1375427e95af5e2e878703.svg","subcategory":"Compilers & Runtimes","website":"https://pytorch.org/xla/release/2.1/index.html","description":"PyTorch runs on XLA devices, like TPUs, with the torch_xla package.","primary_repository_url":"https://github.com/pytorch/xla"},{"category":"Optimizations","id":"optimizations--mlops--accelerate","name":"accelerate","logo":"logos/f975c8a171af33d268543e8ec85de06980f3ddc7069f82db0645d075285c4b1d.svg","subcategory":"MLOps","website":"https://huggingface.co/docs/accelerate/index","description":"Accelerate is a library that enables the same PyTorch code to be run across distributed configurations","primary_repository_url":"https://github.com/huggingface/accelerate"},{"category":"Optimizations","id":"optimizations--mlops--clear-ml","name":"Clear ML","logo":"logos/b8f9b0d3ee7df42d688ddfaf95b3177f256d68521167ac27b601778e339fbedc.svg","subcategory":"MLOps","website":"https://clear.ml/","description":"Suite of tools to streamline your AI workflow.","primary_repository_url":"https://github.com/allegroai/clearml"},{"category":"Optimizations","id":"optimizations--mlops--determined","name":"Determined","logo":"logos/6f06ce54ac2345f4d76475807a8d81d20d4f6d8f1f017ac591fb22f312ef329c.svg","subcategory":"MLOps","website":"https://determined.ai/","description":"Determined is an open-source machine learning platform that simplifies distributed training, hyperparameter tuning, experiment tracking, and resource management. Works with PyTorch and TensorFlow.","primary_repository_url":"https://github.com/determined-ai/determined"},{"category":"Optimizations","id":"optimizations--mlops--forte","name":"forte","logo":"logos/841fb71182aaea1282f014f735fb0f7db557d72aa48bcb0b9807fde0859f958d.svg","subcategory":"MLOps","website":"https://github.com/asyml/forte","description":"Forte is a flexible and powerful ML workflow builder.","primary_repository_url":"https://github.com/asyml/forte"},{"category":"Optimizations","id":"optimizations--mlops--hydra","name":"Hydra","logo":"logos/cccea004a9de0d9bfd5ab086ec975ab271e67b75172e0526d0294b8e158b6db2.svg","subcategory":"MLOps","website":"https://hydra.cc/","description":"simplifies the development of research and other complex applications. The key feature is the ability to dynamically create a hierarchical configuration by composition and override it through config files and the command line. The name Hydra comes from its ability to run multiple similar jobs - much like a Hydra with multiple heads.","primary_repository_url":"https://github.com/facebookresearch/hydra"},{"category":"Optimizations","id":"optimizations--mlops--padl","name":"padl","logo":"logos/c0324d6b677e731d34b894562042072e4a31734082e9134609e1b68c251bc3d9.svg","subcategory":"MLOps","website":"https://lf1-io.github.io/padl/latest/","description":"A pipeline builder for PyTorch.","primary_repository_url":"https://github.com/lf1-io/padl"},{"category":"Optimizations","id":"optimizations--mlops--polyaxon","name":"Polyaxon","logo":"logos/c8eb66406bda3aeb5e725039da192ab06ab57b2fa394f0a8ea06e57997fc48c4.svg","subcategory":"MLOps","website":"https://polyaxon.com/","description":"MLOps Tools For Managing & Orchestrating The Machine Learning LifeCycle","primary_repository_url":"https://github.com/polyaxon/polyaxon"},{"category":"Optimizations","id":"optimizations--distributed--deepspeed","name":"DeepSpeed","logo":"logos/6a721f2f0c7a39901db79faf3d4307b17472c558462574a3ad699666f4d0e3f3.svg","subcategory":"Distributed","website":"https://www.deepspeed.ai/","description":"DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.","primary_repository_url":"https://github.com/microsoft/DeepSpeed"},{"category":"Optimizations","id":"optimizations--distributed--fairscale","name":"FairScale","logo":"logos/76b44191e2f21640c78f4d1afc3679f6bdefb6187441da1a84222ee5be3fb5f7.svg","subcategory":"Distributed","website":"https://github.com/facebookresearch/fairscale","description":"PyTorch extension library for high performance and large scale training. This library extends basic PyTorch capabilities while adding new SOTA scaling techniques.","primary_repository_url":"https://github.com/facebookresearch/fairscale"},{"category":"Optimizations","id":"optimizations--distributed--horovod","name":"Horovod","logo":"logos/a6f46dcbeb116393f35638875cc39a90f61ebc28453af34bf89ce3185da131ae.svg","subcategory":"Distributed","website":"http://horovod.ai/","description":"Horovod is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet","primary_repository_url":"https://github.com/horovod/horovod"}]}