[{"category":"Modeling","homepage_url":"https://advertorch.readthedocs.io/en/latest/","id":"modeling--adversarial-robustness--advertorch","logo_url":"http://127.0.0.1:8000/logos/eec3e6838be8fa53a5d16513a8d774a10163c261bbef2fbb1172f7f33954dfd9.svg","name":"AdverTorch","subcategory":"Adversarial & Robustness","description":"A Toolbox for Adversarial Robustness Research","repositories":[{"url":"https://github.com/BorealisAI/advertorch","primary":true}]},{"category":"Modeling","homepage_url":"https://albumentations.ai/docs/","id":"modeling--computer-vision--albumentations","logo_url":"http://127.0.0.1:8000/logos/9c283e8d47d4c3f87139e047313bbb92c6f038a28d7d1ceea7378542b33b9dd5.svg","name":"Albumentations","subcategory":"Computer Vision","description":"a Python library for image augmentation used in deep learning and computer vision tasks to increase the quality of trained models. The purpose of image augmentation is to create new training samples from the existing data.","repositories":[{"url":"https://github.com/albumentations-team/albumentations","primary":true}]},{"category":"Modeling","homepage_url":"https://allenai.org/allennlp","id":"modeling--language--allennlp","logo_url":"http://127.0.0.1:8000/logos/43d3a869c90be770813540f0fd05114f0250a9fb796e52ed7f7ceb33772ad2ef.svg","name":"AllenNLP","subcategory":"Language","description":"An NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks.","repositories":[{"url":"https://github.com/allenai/allennlp","primary":true}]},{"category":"Modeling","homepage_url":"https://anomalib.readthedocs.io/en/latest/","id":"modeling--computer-vision--anomalib","logo_url":"http://127.0.0.1:8000/logos/79211c70ad6c0b096a678d6642e449e908438c6ba9ea651323b55b258a1a99ac.svg","name":"Anomalib","subcategory":"Computer Vision","description":"An anomaly detection library comprising state-of-the-art algorithms and features such as experiment management, hyper-parameter optimization, and edge inference.","repositories":[{"url":"https://github.com/openvinotoolkit/anomalib","primary":true}]},{"category":"Modeling","homepage_url":"https://captum.ai/docs/introduction.html","id":"modeling--adversarial-robustness--captum","logo_url":"http://127.0.0.1:8000/logos/2abc1fc7558376c329b2798f7bcde761b3644e8805d84dc631370e0e76d75b8d.svg","name":"Captum","subcategory":"Adversarial & Robustness","description":"An open source, extensible library for model interpretability built on PyTorch.","repositories":[{"url":"https://github.com/pytorch/captum","primary":true}]},{"category":"Modeling","homepage_url":"https://clinicadl.readthedocs.io/en/latest/","id":"modeling--medical-biology--clinica-dl","logo_url":"http://127.0.0.1:8000/logos/0e35348df86096d30232c0f852e0821acb387f280097ad52f6b298ee03147ee8.svg","name":"Clinica DL","subcategory":"Medical & Biology","description":"open-source deep learning software for reproducible neuroimaging processing. It can be seen as the deep learning extension of Clinica, an open-source Python library for neuroimaging preprocessing and analysis.","repositories":[{"url":"https://github.com/aramis-lab/clinicadl","primary":true}]},{"category":"Modeling","homepage_url":"https://www.colossalai.org/","id":"modeling--language--colossal-llama-2","logo_url":"http://127.0.0.1:8000/logos/9dad1dc0f5e62ccaae15a7b3d9df96926275a1b075aad0107a87dee756bcf9be.svg","name":"Colossal-LLaMA-2","subcategory":"Language","description":"This project is no longer available","repositories":[{"url":"https://github.com/hpcaitech/ColossalAI/tree/main/applications/Colossal-LLaMA-2","primary":true}]},{"category":"Modeling","homepage_url":"https://detectron2.readthedocs.io/en/latest/","id":"modeling--computer-vision--detectron2","logo_url":"http://127.0.0.1:8000/logos/09c4e847ff560f506f21bd599257ed2204e309e54cfd66f008f2d2c40a46244b.svg","name":"Detectron2","subcategory":"Computer Vision","description":"is a platform for object detection, segmentation and other visual recognition tasks.","repositories":[{"url":"https://github.com/facebookresearch/detectron2","primary":true}]},{"category":"Modeling","homepage_url":"https://www.dgl.ai/","id":"modeling--specialized--dgl","logo_url":"http://127.0.0.1:8000/logos/8bc26a2c13a583b1695caeee24b08ead02adb0d16645e0d2763ea37305fae388.svg","name":"DGL","subcategory":"Specialized","description":"Python package built to ease deep learning on graph, on top of existing DL frameworks.  Fast and memory-efficient message passing primitives for training Graph Neural Networks.","repositories":[{"url":"https://github.com/dmlc/dgl/","primary":true}]},{"category":"Modeling","homepage_url":"https://huggingface.co/docs/diffusers/index","id":"modeling--specialized--diffusers","logo_url":"http://127.0.0.1:8000/logos/ffc8bf3d4d9c6e89044e907ea8b49195426ef764da054041f80845be8605c48e.svg","name":"Diffusers","subcategory":"Specialized","description":"Pretrained diffusion models for generating images, audio, and even 3D structures of molecules. Whether you are looking for a simple inference solution or want to train your own diffusion model, Diffusers is a modular toolbox that supports both","repositories":[{"url":"https://github.com/huggingface/diffusers","primary":true}]},{"category":"Modeling","homepage_url":"https://ensemble-pytorch.readthedocs.io/","id":"modeling--adversarial-robustness--ensemble-pytorch","logo_url":"http://127.0.0.1:8000/logos/1a5daa080e0d4c6242967eeac5734b744501e8d1bfe8a1f86e4305047a928ef0.svg","name":"Ensemble-Pytorch","subcategory":"Adversarial & Robustness","description":"unified ensemble framework for PyTorch to improve the performance and robustness of your ensemble based deep learning model","repositories":[{"url":"https://github.com/TorchEnsemble-Community/Ensemble-Pytorch","primary":true}]},{"category":"Modeling","homepage_url":"https://github.com/flairNLP/flair","id":"modeling--language--flair","logo_url":"http://127.0.0.1:8000/logos/79bb5140f6e438d44b09dbd2bde4ba675f11bb1e19b84e74b0ada9b16c0b034a.svg","name":"Flair","subcategory":"Language","description":"Flair allows you to apply our state-of-the-art natural language processing (NLP) models to your text, such as named entity recognition (NER), sentiment analysis, part-of-speech tagging (PoS), special support for biomedical texts, sense disambiguation and classification, with support for a rapidly growing number of languages","repositories":[{"url":"https://github.com/flairNLP/flair","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorch.org/ecosystem/","id":"modeling--medical-biology--fusemedml","logo_url":"http://127.0.0.1:8000/logos/bed2d7b1ea133092432cc28a1d20d3314098a2c30624894f1bad0ed7162fa03d.svg","name":"FuseMedML","subcategory":"Medical & Biology","description":"A python framework accelerating ML based discovery in the medical field by encouraging code reuse","repositories":[{"url":"https://github.com/BiomedSciAI/fuse-med-ml","primary":true}]},{"category":"Modeling","homepage_url":"https://www.nature.com/articles/s44172-023-00066-3","id":"modeling--medical-biology--gandlf","logo_url":"http://127.0.0.1:8000/logos/2c684fbc52871399018ed1bbd4eb4558cf380b37f789128ab453063f072a1377.svg","name":"GaNDLF","subcategory":"Medical & Biology","description":"The Generally Nuanced Deep Learning Framework (GaNDLF) for image segmentation and classification, especially in the biomedical field.","repositories":[{"url":"https://github.com/mlcommons/gandlf","primary":true}]},{"category":"Modeling","homepage_url":"https://joeynmt.readthedocs.io/en/latest/#","id":"modeling--language--joeynmt","logo_url":"http://127.0.0.1:8000/logos/817179366550e656ee07a69f74369f9b49b23e815c2d4c3d5a092fbf4318dbc9.svg","name":"joeynmt","subcategory":"Language","description":"JoeyNMT is a minimalist neural machine translation toolkit for educational purposes.","repositories":[{"url":"https://github.com/joeynmt","primary":true}]},{"category":"Modeling","homepage_url":"https://kornia.github.io/","id":"modeling--computer-vision--kornia","logo_url":"http://127.0.0.1:8000/logos/68d50512b8d058f5ae4c92b0fdb1a54132e0b208cb573c1b84bb19e7a2cabd4c.svg","name":"Kornia","subcategory":"Computer Vision","description":"Kornia is a geometric computer vision Library for spatial AI library that allows classical computer vision to be integrated into deep learning models.","repositories":[{"url":"https://github.com/kornia/kornia","primary":true}]},{"category":"Modeling","homepage_url":"https://woven-planet.github.io/l5kit/","id":"modeling--specialized--l5kit","logo_url":"http://127.0.0.1:8000/logos/7dabfc94ffc28d1fd628346c3d70bb5a0fa4ae514b5323cad25267cd71aa3fab.svg","name":"L5Kit","subcategory":"Specialized","description":"A python library with functionality for the development and training of learned prediction, planning and simulation models for autonomous driving applications.","repositories":[{"url":"https://github.com/woven-planet/l5kit","primary":true}]},{"category":"Modeling","homepage_url":"https://docs.lightly.ai/self-supervised-learning/","id":"modeling--computer-vision--lightly","logo_url":"http://127.0.0.1:8000/logos/5135c80fa8aeb01b5a93eb51f1c869d3e920e89759d25f423e0edb513df1fd02.svg","name":"Lightly","subcategory":"Computer Vision","description":"LightlySSL is a computer vision framework for self-supervised learning.","repositories":[{"url":"https://github.com/lightly-ai/lightly","primary":true}]},{"category":"Modeling","homepage_url":"https://mmagic.readthedocs.io/en/latest/","id":"modeling--computer-vision--mmediting","logo_url":"http://127.0.0.1:8000/logos/2dd6eb493139d0728db74c27c9fd20e49fc83dd40a459aa1dfee080548d9651b.svg","name":"MMEditing","subcategory":"Computer Vision","description":"Image and Video Restoration, Editing and Generation Toolbox","repositories":[{"url":"https://github.com/open-mmlab/mmediting","primary":true}]},{"category":"Modeling","homepage_url":"https://mmf.sh/","id":"modeling--multimodal--mmf","logo_url":"http://127.0.0.1:8000/logos/0c6791d31524bbcc5d00788ef39db3ff6576fdd3d3b1f8cea530d5c551e9098f.svg","name":"MMF","subcategory":"Multimodal","description":"A modular framework for vision & language multimodal research.","repositories":[{"url":"https://github.com/facebookresearch/mmf","primary":true}]},{"category":"Modeling","homepage_url":"https://monai.io/","id":"modeling--medical-biology--monai","logo_url":"http://127.0.0.1:8000/logos/05c4cdff595fa70e0ca8175384c2fbe4efc7c321437d8fd14bd6f13a9671fb74.svg","name":"MONAI","subcategory":"Medical & Biology","description":"AI Toolkit for Healthcare Imaging","repositories":[{"url":"https://github.com/Project-MONAI","primary":true}]},{"category":"Modeling","homepage_url":"https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html","id":"modeling--multimodal--nemo","logo_url":"http://127.0.0.1:8000/logos/28338dbf8ea96d2f14e1e737ecab8f55ada4616e445a10a89f0cb2c019ee8f14.svg","name":"NeMo","subcategory":"Multimodal","description":"A scalable generative AI framework built for researchers and developers working on Large Language Models, Multimodal, and Speech AI (Automatic Speech Recognition and Text-to-Speech)","repositories":[{"url":"https://github.com/NVIDIA/NeMo","primary":true}]},{"category":"Modeling","homepage_url":"https://opencompass.org.cn/home","id":"modeling--language--opencompass","logo_url":"http://127.0.0.1:8000/logos/7a70f2cbec75cbed6adfa360674d53e5fd6536ee1b342b52588a3dbd35ef8860.svg","name":"OpenCompass","subcategory":"Language","description":"OpenCompass is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets.","repositories":[{"url":"https://github.com/open-compass/opencompass","primary":true}]},{"category":"Modeling","homepage_url":"https://openmmlab.com/","id":"modeling--computer-vision--openmmlab","logo_url":"http://127.0.0.1:8000/logos/4efdc7f99d6658760637db639f854554798b6fac64d661903c68e7728e5014ba.svg","name":"OpenMMLab","subcategory":"Computer Vision","description":"Open-source computer vision algorithms and models.","repositories":[{"url":"https://github.com/open-mmlab","primary":true}]},{"category":"Modeling","homepage_url":"https://parl.ai/","id":"modeling--language--pariai","logo_url":"http://127.0.0.1:8000/logos/0fd85ffd8df76e3a4ece780593d9f95b8c193bf33cf97c16955e93ca59b757fd.svg","name":"ParIAI","subcategory":"Language","description":"A framework for training and evaluating AI models on a variety of openly available dialogue datasets.","repositories":[{"url":"https://github.com/facebookresearch/ParlAI","primary":true}]},{"category":"Modeling","homepage_url":"https://pennylane.ai/","id":"modeling--quantum--pennylane","logo_url":"http://127.0.0.1:8000/logos/2d8e7a169283e296f1d72aad881717481147608ecb440ecb9b92b3c078ce197f.svg","name":"PennyLane","subcategory":"Quantum","description":"PennyLane is a cross-platform Python library for quantum computing, quantum machine learning, and quantum chemistry. Train a quantum computer the same way as a neural network.","repositories":[{"url":"https://github.com/PennyLaneAI/pennylane","primary":true}]},{"category":"Modeling","homepage_url":"https://pypose.org/","id":"modeling--specialized--pypose","logo_url":"http://127.0.0.1:8000/logos/8513a8257efd437369eb631ace0e7514cfdce3e6297154043bc263c67f49d128.svg","name":"PyPose","subcategory":"Specialized","description":"PyPose is a library for Robot Learning with Physics-based Optimization","repositories":[{"url":"https://github.com/pypose/pypose","primary":true}]},{"category":"Modeling","homepage_url":"https://pypots.com/","id":"modeling--specialized--pypots","logo_url":"http://127.0.0.1:8000/logos/9b443ae59bd33bdee86bbe1d3190c727ce938845d8696ac8e76bd7c662c822a2.svg","name":"PyPOTS","subcategory":"Specialized","description":"a Python toolbox for machine learning on Partially-Observed Time Series","repositories":[{"url":"https://github.com/WenjieDu/PyPOTS","primary":true}]},{"category":"Modeling","homepage_url":"https://github.com/pystiche/pystiche","id":"modeling--computer-vision--pystiche","logo_url":"http://127.0.0.1:8000/logos/b024259eacdf1948a9a6dcc2b94a9d67df1e249789ac8d44c6d822e4e7d0cdae.svg","name":"pystiche","subcategory":"Computer Vision","description":"Framework for Neural Style Transfer (NST) built upon PyTorch","repositories":[{"url":"https://github.com/pystiche/pystiche","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorchnlp.readthedocs.io/en/latest/","id":"modeling--language--pytorch-nlp","logo_url":"http://127.0.0.1:8000/logos/49a408722c78586e14156d60f6d32160a69da86afea96b933f3084dc4157c133.svg","name":"PyTorch-NLP","subcategory":"Language","description":"Basic Utilities for PyTorch Natural Language Processing (NLP)","repositories":[{"url":"https://github.com/PetrochukM/PyTorch-NLP","primary":true}]},{"category":"Modeling","homepage_url":"https://torch-points3d.readthedocs.io/en/latest/","id":"modeling--3d--pytorch-points3d","logo_url":"http://127.0.0.1:8000/logos/7c3c77c9fbd88d4dae1e9d32ef70b0b115ad578cacb4f90dda36f4aaefc4cc0d.svg","name":"PyTorch-Points3d","subcategory":"3D","description":"A framework for developing and testing common deep learning models to solve tasks related to unstructured 3D spatial data","repositories":[{"url":"https://github.com/torch-points3d/torch-points3d","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorch3d.org/","id":"modeling--3d--pytorch3d","logo_url":"http://127.0.0.1:8000/logos/88318438fc9c2bbc4989daf11182ed9ec9e685c4f9f97317d978d87f732f9e96.svg","name":"PyTorch3D","subcategory":"3D","description":"PyTorch3D is a library of reusable components for deep learning with 3D data","repositories":[{"url":"https://github.com/facebookresearch/pytorch3d","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorchfi.dev/","id":"modeling--adversarial-robustness--pytorchfi","logo_url":"http://127.0.0.1:8000/logos/4940f3cf2023e817b489c95cca20b0effbac6407db28e7f6eabe7cd4177aa5e5.svg","name":"pytorchfi","subcategory":"Adversarial & Robustness","description":"A runtime fault injection tool for PyTorch","repositories":[{"url":"https://github.com/pytorchfi/pytorchfi","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorchvideo.org/","id":"modeling--specialized--pytorchvideo","logo_url":"http://127.0.0.1:8000/logos/ad52117a8e14a31993e1549cd32f76e6d4ddb403826679eee528774a7404729a.svg","name":"PyTorchVideo","subcategory":"Specialized","description":"A deep learning library for video understanding research.","repositories":[{"url":"https://github.com/facebookresearch/pytorchvideo","primary":true}]},{"category":"Modeling","homepage_url":"https://docs.rastervision.io/","id":"modeling--computer-vision--raster-vision","logo_url":"http://127.0.0.1:8000/logos/7f48d1f43ed40f3c3dda9f013919d00e801e756dabb5def767474c58f08cf117.svg","name":"raster-vision","subcategory":"Computer Vision","description":"Raster Vision is an open source library and framework for Python developers building computer vision models on satellite, aerial, and other large imagery sets (including oblique drone imagery). There is built-in support for chip classification, object detection, and semantic segmentation using PyTorch.","repositories":[{"url":"https://github.com/azavea/raster-vision","primary":true}]},{"category":"Modeling","homepage_url":"https://naver.github.io/roma/","id":"modeling--3d--roma","logo_url":"http://127.0.0.1:8000/logos/854eb858a0e2e8dc7b30e28631988dfc00c97e1775f3e74f3f1b37e2010c5954.svg","name":"RoMa","subcategory":"3D","description":"RoMa (which stands for Rotation Manipulation) provides differentiable mappings between 3D rotation representations, mappings from Euclidean to rotation space, and various utilities related to rotations.","repositories":[{"url":"https://github.com/naver/roma","primary":true}]},{"category":"Modeling","homepage_url":"https://ibm.github.io/simulai/","id":"modeling--specialized--simulai","logo_url":"http://127.0.0.1:8000/logos/52d2378814907baeac4813eba9000d2ac5fb8a804f9c7a621b96003bdc3738e2.svg","name":"SimulAI","subcategory":"Specialized","description":"A toolkit with data-driven pipelines for physics-informed machine learning.","repositories":[{"url":"https://github.com/IBM/simulai","primary":true}]},{"category":"Modeling","homepage_url":"http://textbrewer.hfl-rc.com/","id":"modeling--language--textbrewer","logo_url":"http://127.0.0.1:8000/logos/118f11cf04792d06063ccac1204986dcba4db290f95137e3dca685a27b15bb3d.svg","name":"TextBrewer","subcategory":"Language","description":"A PyTorch-based knowledge distillation toolkit for natural language processing","repositories":[{"url":"https://github.com/airaria/TextBrewer","primary":true}]},{"category":"Modeling","homepage_url":"https://warwick.ac.uk/fac/cross_fac/tia/","id":"modeling--medical-biology--tiatoolbox","logo_url":"http://127.0.0.1:8000/logos/ba4859ff6d65b65bc3b5e1a48fdffcb34c3d0ff8435c11eb1f1aac0120c1224d.svg","name":"TIAToolbox","subcategory":"Medical & Biology","description":"TIAToolbox is a computational pathology toolbox for pathology image analysis.","repositories":[{"url":"https://github.com/TissueImageAnalytics/tiatoolbox","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorch.org/audio/stable/index.html","id":"modeling--specialized--torchaudio","logo_url":"http://127.0.0.1:8000/logos/0479b28282c205dfc796bdfdc0fdffde3f2cb227c4f384acfc82ba54559b73ba.svg","name":"torchaudio","subcategory":"Specialized","description":"Torchaudio is a library for audio and signal processing with PyTorch. It provides I/O, signal and data processing functions, datasets, model implementations and application components.","repositories":[{"url":"https://github.com/pytorch/audio","primary":true}]},{"category":"Modeling","homepage_url":"https://torchdrift.org/","id":"modeling--adversarial-robustness--torchdrift","logo_url":"http://127.0.0.1:8000/logos/7b94cddf3ba924eb7e58f6fb4fb6dab03b4874f5331cf51e61fe7ea15b413d31.svg","name":"TorchDrift","subcategory":"Adversarial & Robustness","description":"TorchDrift is a data and concept drift library for PyTorch. It lets you monitor your PyTorch models to see if they operate within spec.","repositories":[{"url":"https://github.com/TorchDrift/TorchDrift","primary":true}]},{"category":"Modeling","homepage_url":"https://torchdrug.ai/","id":"modeling--medical-biology--torchdrug","logo_url":"http://127.0.0.1:8000/logos/3bfe1124b8618af6e41b5f3da074e88c2bd2ed7a6e1e70cf35dad2f2ecd2ed51.svg","name":"torchdrug","subcategory":"Medical & Biology","description":"A powerful and flexible machine learning platform for drug discovery","repositories":[{"url":"https://github.com/DeepGraphLearning/torchdrug","primary":true}]},{"category":"Modeling","homepage_url":"https://www.osgeo.org/projects/torchgeo/","id":"modeling--specialized--torchgeo","logo_url":"http://127.0.0.1:8000/logos/0f021d5c7b0d805439d23e941b0a743d16b7cf89fa11b5cc9c19a53d44549420.svg","name":"torchgeo","subcategory":"Specialized","description":"TorchGeo is a toolkit containing datasets, samplers, transforms, and pre-trained models for geospatial data.","repositories":[{"url":"https://github.com/microsoft/torchgeo","primary":true}]},{"category":"Modeling","homepage_url":"http://www.torchio.org/","id":"modeling--medical-biology--torchio","logo_url":"http://127.0.0.1:8000/logos/3f53485d82e837e49ad8c2f5b2ca860ac321809c9d7a50f6f4029c49911a158f.svg","name":"TorchIO","subcategory":"Medical & Biology","description":"Medical imaging toolkit for deep learning","repositories":[{"url":"https://github.com/fepegar/torchio","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorch.org/torchrec/","id":"modeling--specialized--torchrec","logo_url":"http://127.0.0.1:8000/logos/6ad59498ae22cd620301645c5c98cdecf5045d2dbe9c02a202c7b754d3c7e1b3.svg","name":"torchrec","subcategory":"Specialized","description":"TorchRec is a specialized library within the PyTorch ecosystem, tailored for building, scaling, and deploying large-scale recommendation systems,","repositories":[{"url":"https://github.com/pytorch/torchrec","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorch.org/rl/stable/index.html","id":"modeling--reinforcement-learning--torchrl","logo_url":"http://127.0.0.1:8000/logos/9e21fff2d388248fd441ac537ca6fbe214c487bd4c9750fdd08ffe7f42c6c111.svg","name":"torchrl","subcategory":"Reinforcement Learning","description":"TorchRL is an open-source Reinforcement Learning (RL) library for PyTorch.","repositories":[{"url":"https://github.com/pytorch/rl","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorch.org/text/stable/index.html","id":"modeling--language--torchtext","logo_url":"http://127.0.0.1:8000/logos/669e1ddb462a51c65757bb21449a8fd161ac796f473c5ee13e67b9ce73d5b784.svg","name":"torchtext","subcategory":"Language","description":"The torchtext package consists of data processing utilities and popular datasets for natural language.","repositories":[{"url":"https://github.com/pytorch/text","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorch.org/torchtune/stable/index.html","id":"modeling--language--torchtune","logo_url":"http://127.0.0.1:8000/logos/650fb24df4978fa6e25d08237b9998598b04c608e482d0a3a1de3716ace1687a.svg","name":"torchtune","subcategory":"Language","description":"A Native-PyTorch library for LLM fine-tuning.","repositories":[{"url":"https://github.com/pytorch/torchtune","primary":true}]},{"category":"Modeling","homepage_url":"https://pytorch.org/vision/stable/index.html","id":"modeling--computer-vision--torchvision","logo_url":"http://127.0.0.1:8000/logos/13688abf6c8188d41c1d80ebeb359bcbc4a572316d5f2601de39c1cf67abe6c5.svg","name":"torchvision","subcategory":"Computer Vision","description":"The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.","repositories":[{"url":"https://github.com/pytorch/vision","primary":true}]},{"category":"Modeling","homepage_url":"https://huggingface.co/transformers","id":"modeling--language--transformers","logo_url":"http://127.0.0.1:8000/logos/22ee2a64b64ec10d3f8665a2c99fe71389da44d177ce9688632c462e8627224b.svg","name":"Transformers","subcategory":"Language","description":"Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.","repositories":[{"url":"https://github.com/huggingface/transformers","primary":true}]},{"category":"Modeling","homepage_url":"https://usb.readthedocs.io/en/main/","id":"modeling--multimodal--usb","logo_url":"http://127.0.0.1:8000/logos/ba2f979d55cfe3b448250c198b2c08437accb672f3f21600f0b3c979a399c9e7.svg","name":"USB","subcategory":"Multimodal","description":"Benchmark tool for developing and evaluating Semi-suprevised learning algorithms.  Includes an implementation of 14 SSL algorithms and 15 tasks for evaluation for CV, NLP, and Audio","repositories":[{"url":"https://github.com/microsoft/Semi-supervised-learning","primary":true}]},{"category":"Modeling","homepage_url":"https://vissl.ai/","id":"modeling--computer-vision--vissl","logo_url":"http://127.0.0.1:8000/logos/016493ec5173a2af3effb4dd26c934658094910366ce5258a8b1534a7d6e5027.svg","name":"VISSL","subcategory":"Computer Vision","description":"A library for state-of-the-art self-supervised learning from images","repositories":[{"url":"https://github.com/facebookresearch/vissl/graphs/commit-activity","primary":true}]}]