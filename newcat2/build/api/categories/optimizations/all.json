[{"category":"Optimizations","homepage_url":"https://huggingface.co/docs/accelerate/index","id":"optimizations--mlops--accelerate","logo_url":"http://127.0.0.1:8000/logos/f975c8a171af33d268543e8ec85de06980f3ddc7069f82db0645d075285c4b1d.svg","name":"accelerate","subcategory":"MLOps","description":"Accelerate is a library that enables the same PyTorch code to be run across distributed configurations","repositories":[{"url":"https://github.com/huggingface/accelerate","primary":true}]},{"category":"Optimizations","homepage_url":"https://clear.ml/","id":"optimizations--mlops--clear-ml","logo_url":"http://127.0.0.1:8000/logos/b8f9b0d3ee7df42d688ddfaf95b3177f256d68521167ac27b601778e339fbedc.svg","name":"Clear ML","subcategory":"MLOps","description":"Suite of tools to streamline your AI workflow.","repositories":[{"url":"https://github.com/allegroai/clearml","primary":true}]},{"category":"Optimizations","homepage_url":"https://www.deepspeed.ai/","id":"optimizations--distributed--deepspeed","logo_url":"http://127.0.0.1:8000/logos/6a721f2f0c7a39901db79faf3d4307b17472c558462574a3ad699666f4d0e3f3.svg","name":"DeepSpeed","subcategory":"Distributed","description":"DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.","repositories":[{"url":"https://github.com/microsoft/DeepSpeed","primary":true}]},{"category":"Optimizations","homepage_url":"https://depyf.readthedocs.io/en/latest/","id":"optimizations--compilers-runtimes--depyf","logo_url":"http://127.0.0.1:8000/logos/e4a063d36b8096ad076ac1c71881f1be4ccc0a18433cd7541d08de40f2c3370f.svg","name":"Depyf","subcategory":"Compilers & Runtimes","description":"depyf is a tool to help you understand debug and get insights into pytorch.compile","repositories":[{"url":"https://github.com/thuml/depyf","primary":true}]},{"category":"Optimizations","homepage_url":"https://determined.ai/","id":"optimizations--mlops--determined","logo_url":"http://127.0.0.1:8000/logos/6f06ce54ac2345f4d76475807a8d81d20d4f6d8f1f017ac591fb22f312ef329c.svg","name":"Determined","subcategory":"MLOps","description":"Determined is an open-source machine learning platform that simplifies distributed training, hyperparameter tuning, experiment tracking, and resource management. Works with PyTorch and TensorFlow.","repositories":[{"url":"https://github.com/determined-ai/determined","primary":true}]},{"category":"Optimizations","homepage_url":"https://einops.rocks/","id":"optimizations--general--einops","logo_url":"http://127.0.0.1:8000/logos/b5a90edf576208a5d90039a11703e94d01d4d4941c3bb98702a13de77d0cbec3.svg","name":"einops","subcategory":"General","description":"Flexible and powerful tensor operations for readable and reliable code (for pytorch, jax, TF and others)","repositories":[{"url":"https://github.com/arogozhnikov/einops","primary":true}]},{"category":"Optimizations","homepage_url":"https://github.com/facebookresearch/fairscale","id":"optimizations--distributed--fairscale","logo_url":"http://127.0.0.1:8000/logos/76b44191e2f21640c78f4d1afc3679f6bdefb6187441da1a84222ee5be3fb5f7.svg","name":"FairScale","subcategory":"Distributed","description":"PyTorch extension library for high performance and large scale training. This library extends basic PyTorch capabilities while adding new SOTA scaling techniques.","repositories":[{"url":"https://github.com/facebookresearch/fairscale","primary":true}]},{"category":"Optimizations","homepage_url":"https://github.com/asyml/forte","id":"optimizations--mlops--forte","logo_url":"http://127.0.0.1:8000/logos/841fb71182aaea1282f014f735fb0f7db557d72aa48bcb0b9807fde0859f958d.svg","name":"forte","subcategory":"MLOps","description":"Forte is a flexible and powerful ML workflow builder.","repositories":[{"url":"https://github.com/asyml/forte","primary":true}]},{"category":"Optimizations","homepage_url":"https://github.com/pytorch/glow","id":"optimizations--compilers-runtimes--glow","logo_url":"http://127.0.0.1:8000/logos/b3b7299a3f02acbea42cc57cc86165e6ca112e2729f9f7c3b5284ec36b263bf8.svg","name":"Glow","subcategory":"Compilers & Runtimes","description":"Glow is a machine learning compiler and execution engine for hardware accelerators. It is designed to be used as a backend for high-level machine learning frameworks. The compiler is designed to allow state of the art compiler optimizations and code generation of neural network graphs","repositories":[{"url":"https://github.com/pytorch/glow","primary":true}]},{"category":"Optimizations","homepage_url":"https://higher.readthedocs.io/en/latest/.","id":"optimizations--general--higher","logo_url":"http://127.0.0.1:8000/logos/1b11a1d950e1c79a1d207dbd7cd3233a207fa9056d41dd6d8f6d826f136038ff.svg","name":"higher","subcategory":"General","description":"higher is a pytorch library allowing users to obtain higher order gradients over losses spanning training loops rather than individual training steps.","repositories":[{"url":"https://github.com/facebookresearch/higher","primary":true}]},{"category":"Optimizations","homepage_url":"http://horovod.ai/","id":"optimizations--distributed--horovod","logo_url":"http://127.0.0.1:8000/logos/a6f46dcbeb116393f35638875cc39a90f61ebc28453af34bf89ce3185da131ae.svg","name":"Horovod","subcategory":"Distributed","description":"Horovod is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet","repositories":[{"url":"https://github.com/horovod/horovod","primary":true}]},{"category":"Optimizations","homepage_url":"https://hydra.cc/","id":"optimizations--mlops--hydra","logo_url":"http://127.0.0.1:8000/logos/cccea004a9de0d9bfd5ab086ec975ab271e67b75172e0526d0294b8e158b6db2.svg","name":"Hydra","subcategory":"MLOps","description":"simplifies the development of research and other complex applications. The key feature is the ability to dynamically create a hierarchical configuration by composition and override it through config files and the command line. The name Hydra comes from its ability to run multiple similar jobs - much like a Hydra with multiple heads.","repositories":[{"url":"https://github.com/facebookresearch/hydra","primary":true}]},{"category":"Optimizations","homepage_url":"https://intel.github.io/intel-extension-for-pytorch/","id":"optimizations--compilers-runtimes--intel-extension-for-pytorch","logo_url":"http://127.0.0.1:8000/logos/149058a8b3c96359ac2f000c8958b4899897602728d52d917f9335d1e0273617.svg","name":"intel-extension-for-pytorch","subcategory":"Compilers & Runtimes","description":"A Python extension to optimize performance on an Intel platform.","repositories":[{"url":"https://github.com/intel/intel-extension-for-pytorch","primary":true}]},{"category":"Optimizations","homepage_url":"https://ivy.dev/","id":"optimizations--general--ivy","logo_url":"http://127.0.0.1:8000/logos/4ac7177a12ab6aa7b56c2420367cbe3b6e1be0de2f9753d69198f5ca9a7731bb.svg","name":"ivy","subcategory":"General","description":"Convert Machine Learning Code Between Frameworks","repositories":[{"url":"https://github.com/ivy-llc/ivy","primary":true}]},{"category":"Optimizations","homepage_url":"https://intel.github.io/neural-compressor/latest/docs/source/Welcome.html","id":"optimizations--general--neural-compressor","logo_url":"http://127.0.0.1:8000/logos/ba40986b1563b5634522df1bb286e54e543fea3a4ce7e5d0f72c2de633c074f5.svg","name":"neural-compressor","subcategory":"General","description":"An open-source Python library supporting popular model compression techniques on all deep learning frameworks.","repositories":[{"url":"https://github.com/intel/neural-compressor","primary":true}]},{"category":"Optimizations","homepage_url":"https://github.com/octoml/octoml-profile","id":"optimizations--compilers-runtimes--octoml-profiler","logo_url":"http://127.0.0.1:8000/logos/6a0430bf99ada8d6b9a2f7c296d8719bd6d5081f40036783c1ee51c58ae73217.svg","name":"OctoML Profiler","subcategory":"Compilers & Runtimes","description":"octoml-profile is a python library and cloud service that enables ML engineers to easily assess the performance and cost of PyTorch models on cloud hardware with state-of-the-art ML acceleration technology.","repositories":[{"url":"https://github.com/octoml/octoml-profile","primary":true}]},{"category":"Optimizations","homepage_url":"https://onnxruntime.ai/","id":"optimizations--compilers-runtimes--onnx-runtime","logo_url":"http://127.0.0.1:8000/logos/a2ab7ad7ece050a1a7e0e667813b6992c1abc606d2112dd11c8c84836b5ba522.svg","name":"ONNX runtime","subcategory":"Compilers & Runtimes","description":"High performance ML inferencing and training accelerator","repositories":[{"url":"https://github.com/microsoft/onnxruntime","primary":true}]},{"category":"Optimizations","homepage_url":"https://lf1-io.github.io/padl/latest/","id":"optimizations--mlops--padl","logo_url":"http://127.0.0.1:8000/logos/c0324d6b677e731d34b894562042072e4a31734082e9134609e1b68c251bc3d9.svg","name":"padl","subcategory":"MLOps","description":"A pipeline builder for PyTorch.","repositories":[{"url":"https://github.com/lf1-io/padl","primary":true}]},{"category":"Optimizations","homepage_url":"https://polyaxon.com/","id":"optimizations--mlops--polyaxon","logo_url":"http://127.0.0.1:8000/logos/c8eb66406bda3aeb5e725039da192ab06ab57b2fa394f0a8ea06e57997fc48c4.svg","name":"Polyaxon","subcategory":"MLOps","description":"MLOps Tools For Managing & Orchestrating The Machine Learning LifeCycle","repositories":[{"url":"https://github.com/polyaxon/polyaxon","primary":true}]},{"category":"Optimizations","homepage_url":"https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/","id":"optimizations--compilers-runtimes--poptorch","logo_url":"http://127.0.0.1:8000/logos/941ac64f6b2ec287a2dfc558c637747c9af0d2acdcf5e6148bdbfc5e2f8a81d5.svg","name":"PopTorch","subcategory":"Compilers & Runtimes","description":"PopTorch is a set of extensions for PyTorch enabling models to be trained, evaluated and used on the Graphcore IPU.","repositories":[{"url":"https://github.com/graphcore/poptorch","primary":true}]},{"category":"Optimizations","homepage_url":"https://pytorch.org/xla/release/2.1/index.html","id":"optimizations--compilers-runtimes--pytorchxla","logo_url":"http://127.0.0.1:8000/logos/56585018fdef58028329687f94025e78d6de2f303e1375427e95af5e2e878703.svg","name":"PyTorchXLA","subcategory":"Compilers & Runtimes","description":"PyTorch runs on XLA devices, like TPUs, with the torch_xla package.","repositories":[{"url":"https://github.com/pytorch/xla","primary":true}]},{"category":"Optimizations","homepage_url":"https://www.nebuly.com/","id":"optimizations--compilers-runtimes--speedster","logo_url":"http://127.0.0.1:8000/logos/ec9ec4b18b7c4f05d7caecffa57b81cf8639ba3442d8cbadba3b2bf53e806961.svg","name":"Speedster","subcategory":"Compilers & Runtimes","description":"Speedster reduces inference costs by leveraging SOTA optimization techniques that best couple your AI models with the underlying hardware (GPUs and CPUs).","repositories":[{"url":"https://github.com/nebuly-ai/optimate/tree/main/optimization/speedster","primary":true}]},{"category":"Optimizations","homepage_url":"https://pytorch.org/tensordict/stable/index.html","id":"optimizations--general--tensordict","logo_url":"http://127.0.0.1:8000/logos/786f206855ed9083bcca983901e4c387fcd90182d555b95254efbe6ca0abbd32.svg","name":"tensordict","subcategory":"General","description":"TensorDict is a dictionary-like class that inherits properties from tensors, such as indexing, shape operations, casting to device etc.","repositories":[{"url":"https://github.com/pytorch/tensordict","primary":true}]},{"category":"Optimizations","homepage_url":"http://tensorly.org/","id":"optimizations--general--tensorly","logo_url":"http://127.0.0.1:8000/logos/d4d2be7563e5a626bf144163697a53e71a99556dc4fdeb8b614bdc7a24793a6e.svg","name":"TensorLy","subcategory":"General","description":"TensorLy is a Python library that aims at making tensor learning simple and accessible. It allows to easily perform tensor decomposition, tensor learning and tensor algebra. Its backend system allows to seamlessly perform computation with NumPy, PyTorch, JAX, TensorFlow, CuPy or Paddle, and run methods at scale on CPU or GPU.","repositories":[{"url":"https://github.com/tensorly/tensorly","primary":true}]},{"category":"Optimizations","homepage_url":"https://pytorch.org/TensorRT/","id":"optimizations--compilers-runtimes--torch-tensorrt","logo_url":"http://127.0.0.1:8000/logos/07dbeb39c385db2b246f1fb02d2534f65455facf03f6249afc3eaf34baaddfc1.svg","name":"Torch-TensorRT","subcategory":"Compilers & Runtimes","description":"Torch-TensorRT is a inference compiler for PyTorch, targeting NVIDIA GPUs via NVIDIA’s TensorRT Deep Learning Optimizer and Runtime.","repositories":[{"url":"https://github.com/RizhaoCai/PyTorch_ONNX_TensorRT","primary":true}]},{"category":"Optimizations","homepage_url":"https://pytorch.org/blog/pytorch-native-architecture-optimization/","id":"optimizations--general--torchao","logo_url":"http://127.0.0.1:8000/logos/638990fe07bc0811e3fe713ae9ed527976ec7a9fb6c85f5c7df7a35dc4067a97.svg","name":"torchao","subcategory":"General","description":"PyTorch library for custom data types & optimizations. Quantize and sparsify weights, gradients, optimizers & activations for inference and training.","repositories":[{"url":"https://github.com/pytorch/ao","primary":true}]},{"category":"Optimizations","homepage_url":"https://pytorch.org/torcharrow/beta/index.html","id":"optimizations--general--torcharrow","logo_url":"http://127.0.0.1:8000/logos/c2dcd89ea2a9e0f9465d2a642e9a85f8811510080684404650682e812dfa7615.svg","name":"torcharrow","subcategory":"General","description":"TorchArrow is a torch.Tensor-like Python DataFrame library for data preprocessing in deep learning. It supports multiple execution runtimes and Arrow as a common format.","repositories":[{"url":"https://github.com/pytorch/torcharrow","primary":true}]},{"category":"Optimizations","homepage_url":"https://torchopt.readthedocs.io/en/latest/","id":"optimizations--general--torchopt","logo_url":"http://127.0.0.1:8000/logos/fa7428c96683f978432a500f84b389bd2f5a07cb9738885282a728a9015c5cfd.svg","name":"Torchopt","subcategory":"General","description":"An efficient library for differentiable optimization built upon PyTorch","repositories":[{"url":"https://github.com/metaopt/TorchOpt","primary":true}]},{"category":"Optimizations","homepage_url":"https://ml.energy/zeus/","id":"optimizations--general--zeus","logo_url":"http://127.0.0.1:8000/logos/88fe3408a97b0da3dfbd5328126047c69b1627ea7655a2379de2169c0dc701c2.svg","name":"Zeus","subcategory":"General","description":"Zeus is a library for measuring the energy consumption of Deep Learning workloads and optimizing their energy consumption.","repositories":[{"url":"https://github.com/ml-energy/zeus","primary":true}]}]